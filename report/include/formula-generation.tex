\chapter{Formula Generation}
\label{ch:formula-generation}
Type systems in programming languages are treated as black boxes from
a programmers point of view. The programmer interacts with the type
system for example via type annotations and receives feedback from the
type system in form of error messages. Errors in the type system are
hard to detect for the programmer, because he cannot be sure if it is
an error in his program or in the type system (or its
implementation). In addition he can only debug his program, because of
the black box view on the type system. Therefore it is desirable to
ensure that the type system has the intended semantics.

Mathematical proofs are used to ensure that a type system has the
intended semantics. A basic property of type systems is safety, which
roughly means ``a well-typed term can never reach a stuck state during
evaluation''\cite{Pierce:2002:TPL:509043}. Those properties can be
proven by hand or with the help of proof assistants. Both methods
require substantial manual effort. In accordance to the goal of the
automated generation of type checkers, we explore how well automated
theorem provers can solve simple propositions and how this can be
exploited in the type checker generation. We generate formulas from
type system specifications to interface with automated theorem
provers.
 
\section{Goals}
The generation of formulas from type system specifications pursues two
goals. The first goal is to represent type system specifications as
formulas suitable for automated theorem provers and to use those as a
basis to prove simple propositions about type systems. In
Section~\ref{sec:constr-templ-optim} we prove propositions that check
the applicability of an optimization. The second goal is to explore
how well automated theorem provers can check if a program is
well-typed. Being able to type check programs using automated theorem
provers provides us with free reference implementations for our type
checker generator. The correctness of those reference implementations
depends only on the translation of type system specifications into
first-order formulas and on the correct implementation of the
automated theorem provers.

%\section{Why First-Order Logic?}
%\subsection{Expressiveness}
%\subsection{Tool-Support}
\section{Translations}
\label{sec:translations}
In this section we explain how we translate type system specifications
into first-order formula. Just context declarations, rules, and
conjectures have an explicit representation as first-order
formulas. The rest of the specification is not directly translated
into first-order formulas and it is only needed to ensure that the
generated formulas are well formed.

We represent contexts as a list like structure. Every context $c$ has
a constant $empty_c$ that represents the empty context and predicate
$bind_c$ that constructs contexts from the inputs and outputs of the
context declaration and a context. The look up of elements in a
context $c$ is modeled by the predicate $lookup_c$. This predicate is
defined inductively by two formulas shown in the following and checks
whether an element is contained in a context. In the base case the
element to look up is the top element of the context. In the step case
the top element is different from the element we search, therefore we
have to proceed with the rest of the context.
\begin{multline}
  \forall e, x_1, \dots, x_n, y_1, \dots, y_m . \\
  (lookup_c(x_1,\dots,x_n,y_1,\dots,y_m,
  bind_c(x_1,\dots,x_n,y_1,\dots,y_m,e)))
\label{formula:context-base}
\end{multline}
\begin{multline}
  \forall e, x_1, \dots, x_n, x_1', \dots, x_n', y_1, \dots, y_m,
  y_1', \dots,
  y_m' . \\
  (x_1 \neq x_1') \land \dots \land (x_n \neq x_n') \land (lookup_c(x_1,
  \dots, x_n, y_1, \dots, y_m, e) \implies \\ lookup_c(x_1, \dots, x_n,
  y_1, \dots, y_m, bind_c(x_1',\dots,x_n',y_1',\dots,y_m',e))
\label{formula:context-step}
\end{multline}\todo{see ragnars comment}

Formula~\ref{formula:context-base} shows the base case of the look up
in context $c$. We translate all non-terminals in the context
declaration tagged as input into variables $x_1 \dots x_n$ and all
tagged as output into variables $y_1 \dots y_m$, respectively. The
variable $e$ represents context. In the base case we apply $lookup_c$
to a context whose outer most $bind_c$ binds an element that is
exactly the element we search. Therefore the element is trivially
contained in the context and the look up succeeds.

Formula~\ref{formula:context-step} models the step case of the look up
in context $c$. We introduce two variables, $x_1,x_1', \dots,
x_n,x_n'$ for non-terminals tagged as input and $y_1,y_1', \dots,
y_m,y_m'$ for non-terminals tagged as output. The intuition of the
formula is that if it is possible to look up an input/output pair in a
context $e$ then we can also look it up in a context that contains an
additional input/output pair. If read with evaluation in mind the
intuition is that if the outermost element is not the element we look
for, i.e.\ all inputs differ, then we have to look into the rest of
the context. We only check the input positions in order to test
whether we have a match to lookup the last element first.\todo{see
  ragnars comment} This
corresponds to the scoping behavior of most programming languages.

\begin{example}
  The following context declaration models a standard identifier to
  type binding. It has two components, identifier as inputs and types
  as outputs.
\begin{lstlisting}[language=sltc]
contexts C := ID{I} x Type{O}
\end{lstlisting}
  For this declaration we generate the following two formulas to model
  the behavior of $lookup_{C}$.
  \begin{align}
    &\forall i, t, e \,.\, (lookup_{C}(i, t, bind_{}(i, t,
    e))) \\
    &\forall i,i',t,t',e \,.\, (lookup_{C}(i, t, e) \land i \neq
    i' \implies lookup_{C}(i, t, bind_{C}(i', t', e))))
  \end{align}
\label{ex:context-formulas}
\end{example}

We translate the \gls{ast} nodes of the programming language directly
into predicates that resemble the program structure. For the
translation we use the following scheme. \gls{ast} nodes of the
following form $Cons(e_1, \dots, e_n)$ are translated into a predicate
of the form $cons(p_1, \dots, p_n)$, where we translate all
constituents $e_i$ into predicates $p_i$ recursively. We create for
each of those predicates the following injectivity and univalence
axioms.
\begin{multline}
  \forall p_1,p_1', \dots, p_n, p_n' \,.\, \\ (cons(p_1, \dots, p_n) =
  cons(p_1', \dots, p_n') \implies (p_1 = p_1') \land \dots \land (p_n
  = p_n'))
\end{multline}
\begin{multline}
  \forall p_1,p_1', \dots, p_n, p_n' \,.\, \\ ((p_1 \neq p_1')
  \lor \dots \lor (p_n \neq p_n') \implies cons(p_1, \dots, p_n) \neq
  cons(p_1', \dots, p_n'))
\end{multline}
\begin{multline}
  \forall x, y, p_1, \dots, p_n \,.\, \\ ((cons(p_1, \dots, p_n) = x
  \land cons(p_1, \dots, p_n) = y) \implies x = y)
\end{multline}

Injectivity and univalence holds by definition for those predicates as
we create those predicates from syntax. These axiom can help theorem
provers to conduct proofs, for examples see
Section~\ref{sec:constr-templ-optim}.

The most important part is the translation of the typing
rules. Depending on whether the typing rule has premises we use either
of the following schema:

\begin{align}
  &\forall FV(c) \,.\, c \\
  &\forall FV(p_1,\dots, p_n, c) \,.\, p_1 \land \dots \land p_n \implies
  c
\label{formula:typing-rule}
\end{align}

The predicates $p_i$ represent the premises and $c$ is the conclusion
of the typing rules, $FV$ computes the free variables. What a typing
rule intuitively expresses is that the conclusion can be derived if
all premises can be derived. In terms of first-order logic ``derived''
means that there exists a proof for the proposition. Therefore we
translate a typing rule without premises into a formula that consists
of the conclusion and all-quantifies all free variables of the
conclusion. Free variables are all-quantified, because we want that
all possible variants of the conclusion are derivable. Typing rules
with premises translate into a single implication. The premise of the
implication is the conjunction of all premises of the typing
rule. This ensures that all premises need to be
derivable/satisfied. The conclusion of the implication is the
conclusion of the typing rule. This is a safe fact, because the
conclusion of the typing rule is derivable if all premises are
derivable, which is exactly the semantics of this implication.

\begin{example}
  The following we have the typing rules \code|T-var| and \code|T-abs|
  from the \gls{pcf} specification.

\begin{minipage}{.30\linewidth}
\begin{lstlisting}[language=sltc]
%x : ~T in $C
============= T-var
$C |- %x : ~T
\end{lstlisting}
\end{minipage}
\begin{minipage}{.64\linewidth}
\begin{lstlisting}[language=sltc]
(%x : ~T1 ; $C) |- ~e : ~T2
==================================== T-abs
$C |- fun %x : ~T1 (~e) : ~T1 -> ~T2
\end{lstlisting}
\end{minipage}

Those are translated into the following first-order formulas.

\begin{multline}
  \forall x, t, e \,.\, (lookup(x, t, e) \implies tcheck(e, var(x), t)))
\end{multline}
\begin{multline}
  \forall c, x, e, t, s \,.\, (tcheck(bind(x, t, c), e, s) \\ \implies
  tcheck(c, fun(param(x, t), e), funtype(t, s)))
\end{multline}
\end{example}

We translate judgments in rules into predicates. The built-in
judgments for equality and inequality are translated into the
primitives of \gls{tptp}.
\section{Implementation}
\label{sec:implementation-fof}
This section describes the implementation details of the translation
from the specification language into first-order formulas.

The implementation is organized in the following steps. At fist, the
module is split up into its components, then we transform contexts,
typing rules, and conjectures into first-order formulas. After that we
create a file for each conjecture which contains all generated
formulas. In the following those steps will be explained in detail.

The strategy \code|make-context-formulas| generates axiom formulas for
each context declaration. For each distinct non-terminal in a context
definition we create a fresh variable name to ensure variable names
are compatible with \gls{tptp}. We transform every context declaration
into Formula~\ref{formula:context-base} and
Formula~\ref{formula:context-step} in our internal representation of
\gls{tptp} formulas. To adhere to the structure of the two formulas,
we split the non-terminals of a context declaration by its
input/output tags and put those tagged as input before those tagged as
outputs. In the generated formulas we replace the non-terminals by the
fresh variables. In case of Formula~\ref{formula:context-step} we
create additional fresh variables for input positions.

To rewrite typing rules into first-order formulas is a bit more
involved than the rewriting of context declarations. The strategy
\code|make-formula| transforms rules into first-order formulas in the
\gls{tptp} format. This strategy rewrites premises and conclusions
into first-order terms using the strategy \code|rewrite|. Premises
are, due to limitations of the \texttt{layout}-rules, not represented
as ordinary lists after parsing. Therefore premises are transformed
into ordinary lists by the generic \texttt{to-list} strategy. Now that
we have first-order terms for the premises and the conclusion, we
collect all free variables that occur in them. In rules variables are
not bound, thus all variables are free. However it is important to
collect only free variables, as conjectures may contain
quantifiers. At last, we put premises, conjecture, and quantification
together to construct a formula in the \gls{tptp} format which has the
structure of Formula~\ref{formula:typing-rule}.

Now we present the details of the \texttt{rewrite} strategy, which
transforms premises and conclusions. We this strategy is defined as a
sequence of two top down traversals. The first traversal is the actual
rewrite of the typing judgments and the second is a special treatment
for strings. The second traversal is necessary to wrap all target
language constructs into the \code|Term| constructor.

We translate parts of the specification language into new \gls{sdf}
syntax definitions as described in
Section~\ref{sec:generate-sdf}. Therefore not all nodes contained in
the \gls{ast} of a specification are known at the time of
implementation. However all those nodes have a regular structure. That
is why it is possible to use the \code|cons#(args)| pattern to extract
the relevant parts in a generic manner. The rule \code|make-aux-cons|
wraps all generic nodes\footnote{Generic nodes of the specification
  language, i.e\ empty context, context binds, context look ups,
  typing judgment and meta-variable nodes.} into the auxiliary
constructor \code|AuxCons| with three parameters, the static part of
the constructor name, the generic part of the constructor name and the
arguments. After this transformation normal pattern matching on
\code|AuxCons| is possible. The strategy \code|rewrite-aux-cons|
transforms those auxiliary constructors into first-order terms.

All nodes in the \gls{ast} of a specification that are not wrapped
into auxiliary constructors are constructors of the target
language. Therefore we attempt to transform each node into an
auxiliary node, in case that succeeds, we rewrite the node into a
first-order term otherwise we wrap the node into the \code|Term|
constructor. It is important to wrap the nodes of the target language
to implement pretty printing.

The second top down traversal wraps all strings that occur in the
parameters of nodes into \code|Term| constructors. As the
specification language has no string nodes, it is safe to transform
all those strings into \code|Term| nodes. If there is no second
traversal a direct transformation leads to infinite recursion as every
string within a \code|Term| constructor would be wrapped again in a
\code|Term| constructor, therefore we need a second traversal.

Conjectures are essentially transformed following the same scheme as
rules, the only difference is that we tag the resulting formulas as
\code|conjecture| and not as \code|axiom|.

\section{Editor Support}
It is possible to use automated theorem provers to type check
conjectures from within the editor. For type checking using automated
theorem provers we transform the specification into first order
formulas and create a file per conclusion, as described in the
previous section. Then we call the automated theorem prover Vampire on
for each resulting file and parse the results. For each conjecture we
visualize in the editor whether the verification succeeded and provide
in case of success the names of the used first-order formulas.

We provide also a consistency test for specifications. This check
attempts a proof of \code|1 = 0| with vampire using the first-order
formulas generated from the specification. This method allows us to
possibly find inconsistencies in the type system
specification. However, due to the embedding into first-order logic
and Gödel's second incompleteness theorem it is not possible to proof
within first-order logic that the type system is consistent.

%\section{Performance}
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report"
%%% End:
