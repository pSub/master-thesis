\chapter{Formula Generation}
\label{ch:formula-generation}
Type systems in programming languages can be treated as black boxes
from a programmers point of view. The programmer interacts with the
type system for example via type annotations and receives feedback
from the type system in form of error messages. Errors in the type
system are hard to detect for the programmer, because he cannot be
sure if it is an error in his program or in the type system (or its
implementation). In addition he can only debug his program, because of
the black box view on the type system. Therefore it is desirable to
ensure that the type system has the intended semantics.

Mathematical proofs are used to ensure that a type system has the
intended semantics. A basic property of type systems is safety, which
roughly says ``a well-typed term can never reach a stuck state during
evaluation''\cite{Pierce:2002:TPL:509043}. Those properties can be proven by
hand or with the help of proof assistants. Both methods require
substantial manual effort. In accordance to the goal of the automated
generation of type checkers, we explore how well automated theorem
provers can solve simple propositions and how this can be exploited in
the type checker generation. We generate formulas from type system
specifications to interface with automated theorem provers.
 
\section{Goals}
With generation formulas from type system specification we pursue two
goals. The first goal is to resemble type system specifications
in formulas suitable for automated theorem provers and to use this as
a basis to prove simple properties. The second goal is to explore how
well automated theorem provers can check if a program is well-typed.

\section{Why First-Order Logic?}
\subsection{Expressiveness}
\subsection{Tool-Support}
\section{Translations}
\label{sec:translations}
We translate contexts declarations, rules and conjectures in to
first-order formulas. The rest of the specification is not directly
translated into first-order formulas and only needed to ensure that
the generated formulas are well formed.

\todo[inline]{Implement imports and describe how they are handled.}

We translate context declarations in a uniform way into first-order
formulas. For every context we generate two formulas, which model the
look up of entries in the context. We have defined the context look
up recursively. In the base case the element we lookup is the first
element of the context and in the step case, the first element is
different from the element we search, therefore we have to look in the
rest of the context for it.

\begin{figure}
\begin{multline}
  \forall e, x_1, \dots, x_n, y_1, \dots, y_m . \\
  (lookup_c(x_1,\dots,x_n,y_1,\dots,y_m,
  bind_c(x_1,\dots,x_n,y_1,\dots,y_m,e)))
\label{formula:context-base}
\end{multline}
\caption{Base case of context lookup}
\end{figure}

The Formula~\ref{formula:context-base} is the context look up base
case for a context declared as $c$. We translate all non-terminals in
the context declaration tagged as input into variables $x_1 \dots x_n$
and all tagged as output into variables $y_1 \dots y_m$,
respectively. The variable $e$ represents all possible contexts. For
each context declaration there is a specialized $bind_c$ predicate
which models the binding of an input/output pair to a context $e$. In
the implementation the order of arguments differs, but this difference
is for the discussion of the concept negligible. For details see
Section~\ref{sec:implementation-fof}. There is also a specialized
$lookup_c$ predicate for each context declaration which models the
actual look up in the context. This predicate checks whether some
input/output pair exists in a context. In the base case we apply
$lookup_c$ to a context that we extended with $bind_c$ with exactly
the element we want to look up. Therefore the element is trivially
contained in the context and the look up succeeds.

\begin{figure}
\begin{multline}
  \forall e, x_1, \dots, x_n, x_1', \dots, x_n', y_1, \dots, y_m,
  y_1', \dots,
  y_m' . \\
  (x_1 \neq x_1') \land \dots \land (x_n \neq x_n') \land (lookup_c(x_1,
  \dots, x_n, y_1, \dots, y_m, e) \implies \\ lookup_c(x_1, \dots, x_n,
  y_1, \dots, y_m, bind_c(x_1',\dots,x_n',y_1',\dots,y_m',e))
\label{formula:context-step}
\end{multline}
\caption{Step case of context lookup}
\end{figure}

Formula~\ref{formula:context-step} models the context look up step
case of context $c$. We introduce for each non-terminal two variables,
$x_1,x_1', \dots, x_n,x_n'$ for non-terminals tagged as input and
$y_1,y_1', \dots, y_m,y_m'$ for non-terminals tagged as output. The
intuition of the formula is that if we can look up some input/output
pair in a context $e$ then we can also look it up in an context that
contains and additional input/output pair.

We translate the \gls{ast} nodes of the programming language directly
into predicates that resemble the program structure. For the
translation we use following scheme. We translate a \gls{ast} node of
the following form $Cons(e_1, \dots, e_n)$ into a predicate of the
form $cons(p_1, \dots, p_n)$, where we translate all constituents
$e_i$ into predicates $p_i$ recursively. We create for each of those
predicates injectivity and univalence axioms. Injectivity and
univalence holds by definition as we create those predicates from
syntax. These axiom can help theorem provers to conduct proofs, for
examples see Section~\ref{sec:constr-templ-optim}.

The most important part is the translation of the typing
rules. Depending on whether the typing rules has premises we use
either of the following schema:

\begin{figure}
\begin{align}
  &\forall FV(c) .& c \\
  &\forall FV(p_1,\dots, p_n, c) .& p_1 \land \dots \land p_n \implies
  c
\label{formula:typing-rule}
\end{align}
\caption{Formulas representing typing rules}
\end{figure}

The predicates $p_i$ represent the premises and $c$ is the conclusion
of the typing rules. The intuition of a typing rule is that the
conclusion can be derived if all premises can be derived. In terms of
first-order logic ``derived'' means for arbitrary formulas that there
is a proof and for predicates that the predicate holds under the given
interpretation. Therefore a typing rule without premises is translated
into a formula that consists of the conclusion and all-quantifies all
free variables of the conclusion. Free variables are all-quantified,
because all possible variants of the conclusion have to be derivable.
Typing rules with premises are translated into a single
implication. The premise of the implication is the conjunction of all
premises of the typing rule. This ensures that all premises need to be
derivable/satisfied. The conclusion of the implication is the
conclusion of the typing rule. This makes sense as the intuition was,
that the conclusion of the typing rule is derivable if all premises
are derivable, which is exactly the semantics of this implication.

Type judgments are translated into simple predicates. Equality and
inequality can be expressed via judgments with the annotation ``is
Eq'' and ``is Neq'', respectively. Those judgments must have exactly
two non-terminals.
\section{Implementation}
\label{sec:implementation-fof}
The implementation details of the translation from the specification
language into first-order formula is described in this section.

\todo[inline]{Extend for imports.}
The implementation is organized in the following steps. Fist, the
module is split up into its components. Those are: module description,
imports, programming language, meta-variables, contexts,
judgments, typing rules and conjectures. Second, contexts, typing
rules and conjectures are transformed into first-order
formulas. Third, for each conjecture a file is created which contains
all generated formulas. In the following those steps are explained in
detail.

The module is split up by pattern matching. For formula generation
only the context definitions, typing rules and conjectures are
used.

Formulas for the context definitions are generated for each context
definition separately and are added to the axioms. The non-terminals
of an context definition are indexed with fresh names. Those fresh
names will be used as variables in the first-order formulas. The
structure of the formulas, as it is defined
in~\ref{formula:context-base} and~\ref{formula:context-step}, is
hard-coded in the internal representation for first-order formulas. To
adhere to this structure the variables representing the non-terminals
are split up by their input/output attribute. The counter parts for
the variables needed in the step case are created by appending an
underscore to the variable name, as a tick is not valid in \gls{tptp}.

Rewriting typing rules into first-order formulas is the most complex
process in the formula generation. The rewrite process is triggered
when a typing rule is encountered. When a typing rule with premises is
encountered the premises and conjectures are rewritten by the strategy
\texttt{rewrite}. Premises are, due to limitations of the
\texttt{layout}-rules, not represented as ordinary lists after
parsing. Therefore these special lists are transformed into an
ordinary list by the generic \texttt{to-list} strategy. Then the
free variables of premises and constraints are collected. Now an
implication is constructed from the list of premises and the
conclusion and in the case there are free variables, those variables
are all quantified. By now the constructed formula has the structure
shown in~\ref{formula:typing-rule}.

Now the details of the \texttt{rewrite} strategy are presented. This
strategy is defined as a sequence of two top down traversals. The first
traversal is the actual rewrite of the typing judgments and the second
is a special treatment for strings. The first traversal is organized
as follows. An attempt to rewrite the current node into an auxiliary
constructor is made, if this attempt succeeds the auxiliary
constructor is rewritten into a term of the first-order formula
language, if it does not succeed it is wrapped into the \texttt{Term}
constructor. The reasoning is the following. Some \gls{ast} nodes of the
specification language are generic, those referring to the context
formulas, to the typing judgments and to the meta-variables. Those
consist of some constant string plus some user defined
string. Therefore it is not possible to use normal pattern matching on
them. The only chance to cope with them is to use the generic
\texttt{cons\#(args)} pattern, to access the name of the constructor
as a string. The auxiliary constructor \texttt{AuxCons} is used to
abstract over this generic pattern. The rule \texttt{makeAuxCons}
splits the constructor name into the constant string and the user
defined one and provides the arguments as they are. After this
transformation it is possible to use normal pattern matching on
\texttt{AuxCons}. \texttt{makeAuxCons} only succeeds on the
constructors mentioned before. If a node can be transformed into an
auxiliary constructor the constructor is rewritten immediately
afterwards into a constructor of the first-order logic target
language. These rewritings are trivial mappings from auxiliary
constructors to constructors of the target language. If a
transformation into an auxiliary constructor is not possible, the
current node is wrapped into a \texttt{Term} constructor if it is not
a constructor of the target language. The constructor \texttt{Term}
indicates that the wrapped constructor is a constructor of the
programming language, i.e.\ no constructor of the specification, nor of
the target language. This wrapping is needed for controlled pretty
printing of programming language constructors. In the second top down
traversal strings in the arguments of predicates (\texttt{Pred}) and
term (\texttt{Term}) constructors are wrapped into a \texttt{Term}
constructor to handle constructors without parameters. This wrapping
is needed later on to provide inequalities of constants symbols.

The rewriting of typing rules and conjectures is very similar,
therefore only the differences to the rewriting of typing rules are
described. Conjectures are as their name suggests rewritten into
formulas tagged as conjectures and are therefore also named
\texttt{goal} if no name is specified. \todo[inline]{Are there more
  differences}

\section{Performance}
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report"
%%% End: 




