\chapter{Formula Generation}
\label{ch:formula-generation}
Type systems in programming languages can be treated as black boxes
from a programmers point of view. The programmer interacts with the
type system for example via type annotations and receives feedback
from the type system in form of error messages. Errors in the type
system are hard to detect for the programmer, because he cannot be
sure if it is an error in his program or in the type system (or its
implementation). In addition he can only debug his program, because of
the black box view on the type system. Therefore it is desirable to
ensure that the type system has the intended semantics.

Mathematical proofs are used to ensure that a type system has the
intended semantics. A basic property of type systems is safety, which
roughly says ``a well-typed term can never reach a stuck state during
evaluation''\cite{Pierce:2002:TPL:509043}. Those properties can be proven by
hand or with the help of proof assistants. Both methods require
substantial manual effort. In accordance to the goal of the automated
generation of type checkers, we explore how well automated theorem
provers can solve simple propositions and how this can be exploited in
the type checker generation. We generate formulas from type system
specifications to interface with automated theorem provers.
 
\section{Goals}
With generation formulas from type system specification we pursue two
goals. The first goal is to resemble type system specifications
in formulas suitable for automated theorem provers and to use this as
a basis to prove simple properties. The second goal is to explore how
well automated theorem provers can check if a program is well-typed.

\section{Why First-Order Logic?}
\subsection{Expressiveness}
\subsection{Tool-Support}
\section{Translations}
\label{sec:translations}
We translate contexts declarations, rules and conjectures in to
first-order formulas. The rest of the specification is not directly
translated into first-order formulas and only needed to ensure that
the generated formulas are well formed.

\todo[inline]{Implement imports and describe how they are handled.}

We translate context declarations in a uniform way into first-order
formulas. For every context we generate two formulas, which model the
look up of entries in the context. We have defined the context look
up recursively. In the base case the element we lookup is the first
element of the context and in the step case, the first element is
different from the element we search, therefore we have to look in the
rest of the context for it.

\begin{figure}
\begin{multline}
  \forall e, x_1, \dots, x_n, y_1, \dots, y_m . \\
  (lookup_c(x_1,\dots,x_n,y_1,\dots,y_m,
  bind_c(x_1,\dots,x_n,y_1,\dots,y_m,e)))
\label{formula:context-base}
\end{multline}
\caption{Base case of context lookup}
\end{figure}

The Formula~\ref{formula:context-base} is the context look up base
case for a context declared as $c$. We translate all non-terminals in
the context declaration tagged as input into variables $x_1 \dots x_n$
and all tagged as output into variables $y_1 \dots y_m$,
respectively. The variable $e$ represents all possible contexts. For
each context declaration there is a specialized $bind_c$ predicate
which models the binding of an input/output pair to a context
$e$. There is also a specialized $lookup_c$ predicate for each context
declaration which models the actual look up in the context. This
predicate checks whether some input/output pair exists in a
context. In the base case we apply $lookup_c$ to a context that we
extended with $bind_c$ with exactly the element we want to look
up. Therefore the element is trivially contained in the context and
the look up succeeds.

\begin{figure}
\begin{multline}
  \forall e, x_1, \dots, x_n, x_1', \dots, x_n', y_1, \dots, y_m,
  y_1', \dots,
  y_m' . \\
  (x_1 \neq x_1') \land \dots \land (x_n \neq x_n') \land (lookup_c(x_1,
  \dots, x_n, y_1, \dots, y_m, e) \implies \\ lookup_c(x_1, \dots, x_n,
  y_1, \dots, y_m, bind_c(x_1',\dots,x_n',y_1',\dots,y_m',e))
\label{formula:context-step}
\end{multline}
\caption{Step case of context lookup}
\end{figure}

Formula~\ref{formula:context-step} models the context look up step
case of context $c$. We introduce for each non-terminal two variables,
$x_1,x_1', \dots, x_n,x_n'$ for non-terminals tagged as input and
$y_1,y_1', \dots, y_m,y_m'$ for non-terminals tagged as output. The
intuition of the formula is that if we can look up some input/output
pair in a context $e$ then we can also look it up in an context that
contains and additional input/output pair.

We translate the \gls{ast} nodes of the programming language directly
into predicates that resemble the program structure. For the
translation we use following scheme. We translate a \gls{ast} node of
the following form $Cons(e_1, \dots, e_n)$ into a predicate of the
form $cons(p_1, \dots, p_n)$, where we translate all constituents
$e_i$ into predicates $p_i$ recursively. We create for each of those
predicates injectivity and univalence axioms. Injectivity and
univalence holds by definition as we create those predicates from
syntax. These axiom can help theorem provers to conduct proofs, for
examples see Section~\ref{sec:constr-templ-optim}.

The most important part is the translation of the typing
rules. Depending on whether the typing rules has premises we use
either of the following schema:

\begin{figure}
\begin{align}
  &\forall FV(c) .& c \\
  &\forall FV(p_1,\dots, p_n, c) .& p_1 \land \dots \land p_n \implies
  c
\label{formula:typing-rule}
\end{align}
\caption{Formulas representing typing rules}
\end{figure}

The predicates $p_i$ represent the premises and $c$ is the conclusion
of the typing rules. Intuitively a typing rule expresses is that the
conclusion can be derived if all premises can be derived. In terms of
first-order logic ``derived'' means for that there exists a proof for
the proposition. Therefore we translate a typing rule without premises
into a formula that consists of the conclusion and all-quantifies all
free variables of the conclusion. Free variables are all-quantified,
because we want that all possible variants of the conclusion are
derivable. Typing rules with premises translate into a single implication. The
premise of the implication is the conjunction of all premises of the
typing rule. This ensures that all premises need to be
derivable/satisfied. The conclusion of the implication is the
conclusion of the typing rule. This is safe as the intuition was, that
the conclusion of the typing rule is derivable if all premises are
derivable, which is exactly the semantics of this implication.

We translate judgments in rules into predicates. The built-in
judgments for equality and inequality are translated into the
primitives of \gls{tptp}.
\section{Implementation}
\label{sec:implementation-fof}
This section describes the implementation details of the translation
from the specification language into first-order formulas.

\todo[inline]{Extend for imports.}

The implementation is organized in the following steps. Fist, the
module is split up into its components, then we transform contexts,
typing rules and conjectures into first-order formulas. After that we
create for each conjecture a file which contains all generated
formulas. In the following we explain those steps in detail.

The strategy \verb|make-context-formulas| generates axiom formulas for
each context declaration. For each distinct non-terminal in a context
definition we create a fresh variable name, to ensure variables names
are compatible with \gls{tptp}. We transform every context declaration
into Formula~\ref{formula:context-base} and
Formula~\ref{formula:context-step} in our internal representation of
\gls{tptp} formulas. To adhere to the structure of the two formulas,
we split the non-terminals of a context declaration by its
input/output tags and put those tagged as input before those tagged as
outputs. In the generated formulas we replace the non-terminals by the
fresh variables. In case of Formula~\ref{formula:context-step} we
create additional fresh variables for input positions.

Rewriting typing rules into first-order formulas is a bit more
involved than the rewriting of context declarations. The strategy
\verb|make-formula| transforms rules into first-order formulas in the
\gls{tptp} format. This strategy rewrites premisses and conclusions
into first-order terms using the strategy \verb|rewrite|. Premises
are, due to limitations of the \texttt{layout}-rules, not represented
as ordinary lists after parsing. Therefore premisses are transformed
into ordinary lists by the generic \texttt{to-list} strategy. Now that
we have first-order terms for the premisses and the conclusion, we
collect all free variables that occur in them. In rules variables are
not bound, thus all variables are free. However it is important to
collect only free variables as conjectures may contain quantifiers. As
the last step, we put those pieces together to construct a formula in
the \gls{tptp} format hat has the structure of
Formula~\ref{formula:typing-rule}.

Now we present the details of the \texttt{rewrite} strategy, which
transforms premisses and conclusions. We defined this strategy as a
sequence of two top down traversals. The first traversal is the actual
rewrite of the typing judgments and the second is a special treatment
for strings. The second traversal is necessary to wrap all target
language constructs into the \ver|Term| constructor.

We translate parts of the specification language into new \gls{sdf}
syntax definitions as described in
Section~\ref{sec:generate-sdf}. Therefore not all nodes contained in
the \gls{AST} of a specification are known at the time of
implementation. However all those nodes have a regular structure. That
makes it possible to use the \verb|cons#(args)| pattern to extract the
relevant parts in a generic manner. The rule \verb|make-aux-cons|
wraps all generic nodes (empty context, context binds, context look
up, typing judgment and meta-variable nodes) into the auxiliary
constructor \verb|AuxCons| with three parameters, the static part of
the constructor name, the generic part of the constructor name and the
arguments. After this transformation normal pattern matching on
\verb|AuxCons| is possible. The strategy \verb|rewrite-aux-cons|
transforms those auxiliary constructors in first-order terms.

All nodes in the \gls{ast} of a specification that are not wrapped
into auxiliary constructors are constructors of the target
language. Therefore we attempt to transform each node into an
auxiliary node. If that succeeds, we rewrite the node into a
first-order term otherwise we wrap the node into the \verb|Term|
constructor. Wrapping the nodes of the target language is important
for pretty printing.

The second top down traversal wraps all strings that occur in the
parameters of nodes into \verb|Term| constructors. It is safe to
transform all those strings as the specification language has no
string nodes. We need this second traversal as a direct transformation
would lead to infinite recursion because every string within a
\verb|Term| constructor would we wrapped again in a \verb|Term|
constructor.

Conjectures are essentially transformed as rules, the only difference
is that we tag the resulting formulas as \verb|goal| and not as
\verb|axiom|.
\section{Performance}
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report"
%%% End: 




