
\chapter{Preliminaries}
\section{Tools}
This section introduces the tools and concepts used in this
thesis. The capabilities and usage of the tools is presented and it is
argued for what purpose they are used and why they are suite for those
purposes.
\subsection{SDF}
\gls{sdf}~\cite{Heering:1989:SDF:71605.71607} is a formalism to define
the syntax of formal languages in the tradition of
\gls{bnf}. \gls{sdf} allows to define lexical and context-free
grammars and is, in contrast to \gls{bnf}, modular. This modularity
allows to compose \gls{sdf} syntax definitions. There are also parser
generators for \gls{sdf}, see~\cite{Rekers92parsergeneration}. In
contrast to formalisms for traditional parser generators like
Yacc\cite{Johnson75yacc:yet}, \gls{sdf} specifications are purely
declarative, which increases the reusability of the specifications.

The modularity of \gls{sdf} is a consequence of the fact that
\gls{sdf} is \textit{generalized LR
  parsable}\cite{Rekers92parsergeneration}. Generalized parsing means
that parsing might be indeterminate, i.e.\ the parser produces all
possibilities for syntactic ambiguities. This might not seem to be an
advantage, but generalized parsing has some nice implications. First,
the class of supported grammars is bigger and therefore enforces less
restrictions on the programmer and might allow a natural definition of
languages. Second, it enables the modularity of \gls{sdf}, because
composition of normal LR grammars is not guaranteed to be an LR
grammar again, but this is guaranteed for generalized LR grammars.

An other advantage is that \gls{sdf} is also scannerless
parsable~\cite{Brand02disambiguationfilters}, that means that
tokenization and parsing can be done in a single step.

\gls{sdf} also has support to specify layout sensitive
languages\cite{conf/sle/ErdwegRKO12} like Python or Haskell. Context
insensitive layout constraints are enforced at parse time and context
sensitive constraints are enforced at disambiguation time, i.e.\ all
ambiguities that violate layout constraints are removed.

\begin{example}{~}
\begin{verbatim}
module Bool
exports
  context-free start-symbols Bool
  sorts Bool
  context-free syntax
    "true"  -> Bool
    "false" -> Bool
    Bool "&" Bool -> Bool {cons("And"),
                           layout("2.first.col < 2.left.col")}
\end{verbatim}
\label{ex:sdf-grammar}
\end{example}

Example~\ref{ex:sdf-grammar} shows a grammar that allows to write
conjunctions of \verb|true| and \verb|false|. Conjunctions are
represented in the \gls{ast} with the constructor \verb|And| and the
layout constraint enforces, that if conjunctions span over multiple
lines, the right-hand side of \verb|&| needs to be indented.

\gls{sdf} is used in this thesis to define the syntax of the
specification language for type systems and for the target
languages. Features like layout constraints make \gls{sdf} a good tool
for defining complex syntax for natural deduction rules. The
modularity and composability make it possible to define the syntax of
the specification language independent of the target language.
\subsection{Stratego/XT}
Stratego~\cite{Visser01} is a framework for the development of
transformation systems. It consists of the transformation language
Stratego and a set of tools (XT) for tasks like parsing and pretty
printing. The paradigm of Stratego is to use user-definable strategies
for rewriting. In Stratego the following abstraction levels can be
distinguished.

\begin{description}
\item[Transformation rules] are basic rewrite rules on the structure
  of the \gls{ast}.
\item[Transformation strategies] are the glue between the
  transformation rules. They combine rules, define the order of
  application and the traversal order of the \gls{ast}. These
  strategies can be defined generically. Context information are
  passed using \textit{scoped dynamic rewrite
    rules}~\cite{Visser01scopeddynamic} during the traversal, because
  normal rewrite rules are context-free.
\item[Transformation tools] allow to compile transformation strategies
  into a stand-alone program. The interface between such programs is
  the ATerm format for \glspl{ast}.
\item[Transformation systems] describe a set of programs created by
  the transformation tools, that form a source-to-source
  transformation usually including a parser and pretty printer.
\end{description}

\todo[inline]{Create and explain an small example}

Stratego interacts well with \gls{sdf} and has facilities to integrate
nicely into tool-chains. In addition it allows to write abstract and
generic transformation. That makes it a good choice for the
transformation system.
\subsection{Spoofax}
\todo[inline]{Citations needed.}
Spoofax started with the goal to provide an \gls{ide} for \gls{sdf} and
Stratego. It was then developed to a language workbench for Eclipse
that allows language development with editor support for both, the
languages used for development and the developed language. Smooth
switching between both editor services. The editor for the developed
language can be deployed standalone. Those editor services provide
syntactic and semantic analysis based on live parses, with error
recovery and origin tracking. Those facilities are implemented
language pragmatic, which allows developers to focus on language
specific parts.

Spoofax is used in this thesis to provide editor support for the
specification language and as glue between \gls{sdf} and Stratego in the
development of the specification language, the formula generator and
the type checker generator.
\subsection{Alternatives}
\section{Type Systems}
\textit{Type theory} started as an attempt by Gottlob Frege to solve Russel's
paradox, that shows that \naive{} set theory is inconsistent. Frege
argued that a predicate requires an object as argument and cannot have
itself as an argument, as it is the subject.\todo{Make this more
  precise} So the initial motivation for type theory was to avoid
paradoxes and contradictions in logics and rewrite systems. The term
\textit{type system} refers to type theories whose logics rewrite
systems are programming languages. Type systems address therefore
similar problems as general type theory. The problem they address is
to ensure that programs have meaning, whereas in type theory the
problem is the ensure the consistency of a logic.

What does it mean to ``ensure that programs have meaning''. First, it
means that one wants to filter the useful programs. It is not useful
to have a syntactically valid program that has no semantics. This is
done by assigning types to the expressions of the program. A
\textit{type checker} can then check, whether those types match with
the expressions. If the type checker succeeds the program is
\textit{well-typed} and has meaning. Second, a type system allows to
establish abstractions through user definable data types. When type
checking a program, it is also ensured that those abstractions are not
violated.\footnote{This is only true for so called ``strong'' type
  systems.} In this thesis \textit{static} type systems are
considered. In a static type system types are checked prior to
execution. This early checks can provide guarantees about the programs
behavior 
\section{First-Order Logic}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report"
%%% End: 
