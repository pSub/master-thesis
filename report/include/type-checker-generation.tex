\chapter{Type Checker Generation}
\todo[inline]{Terminology: Type Checker vs. Type Inference}
\section{Goals}
This section briefly describes and motivates the design and goals of
the type checker generator.

The first goal is to produce fast type checkers, even if the type
system specification is not geared towards performance. Mainly this
means to try to deal with non-syntax directed typing rules without
backtracking. The motivation for this is that non-syntax directed
typing rules are often more readable and changes have mainly local
effects.

The second goal is to design a modular type checker generator. A type
checker generator that can be easily adapted and that facilitates the
exchange of components. This modularity is desirable because it
increases the reusability and makes it possible to combine previously
unrelated projects.

The third goal is to generate type checkers that emit readable error
messages if a program is not well-typed. This is essential to make the
generated type checker usable in any way.
\section{Architecture}
The type checker generator has two phases: Template generation and
template optimization. The template generation phase transforms the
type system specification with minor modifications into templates. A
template is a different representation for a typing rule, that is
better suited for type checking. We introduce templates in detail in
Section~\ref{sec:constraint-templates}. The template optimization
phase optimizes checks which optimizations apply to those templates
and applies them. The optimizations aim to reduce the amount of
non-determinism in the type system and therefore reduce the amount of
backtracking in the type checker. The final product after those two
phases is a file that contains the optimized templates.

Instead of generating a type checker directly from the specification,
we implement a generic constraint-based type checker that takes
templates as input. This generic type checker has two phases:
Constraint generation and constraint solving. The constraint
generation phase has the templates and the expression that shall be
type check as input. We then build a derivation tree according to the
expression by pattern matching the conclusion of the
templates. Building and traversing of the derivation tree emits
constraints. The constraint solving phase then tries unify the emitted
constraints. If that succeeds it reports the result otherwise it
reports the errors that occurred during unification.

Figure~\ref{fig:phases} shows the phases and their
relationships. Nodes represent phases and arrows express that data flows
from one node to an other. Labels on arrows describe the data format.

The four phases correspond to modules or tools. Each phase has a
well-defined interface, therefore the implementation can be exchanged
freely. This makes it possible to use different constraint solvers,
constraint generators or template optimizers.

\begin{figure}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,align=center,node distance=2cm,
  thick,main node/.style={rectangle,fill=blue!20,draw,font=\small\bfseries}]

  \node[main node] (1) {Template Generation};
  \node[main node] (2) [right=3cm of 1] {Template Optimization};
  \node[main node] (3) [below of=2] {Constraint Generation};
  \node[main node] (4) [below of=1] {Constraint Solving};
  \coordinate [below right of=3] (5);
  \coordinate [above of=1] (6);

  \path[every node/.style={font=\small}]
    (1) edge node [right, below] {Templates} (2)
    (2) edge node [right] {Extended Templates} (3)
    (5) edge node [right] {Program} (3)
    (3) edge node [right, below] {Constraints} (4)
    (6) edge node [right] {Specification} (1);
\end{tikzpicture}
\caption{Phases of the type checker generator}
\label{fig:phases}
\end{figure}
\section{Implementation}
\label{sec:implementation}
The following sections describe the implementation of the type checker
generator, one section per phase.

\subsection{Template Generation}
\label{sec:constraint-templates}
The first phase translates type system specifications into
templates. This phase is not just a simple translation from a human
readable representation into a representation suitable for programs,
but also normalizes the resulting templates. Normalization comprises
the elimination of implicit equalities and resolves dependencies
between premisses. All following phases assume normalized templates,
which simplifies parts of them.

\subsubsection{Templates}
A template is an intermediate representation of a typing rule that is
more suitable for the constraint generation process and defined as
following.

Templates serve as the input format for the constraint generation
phase of the type checker. Besides being better suited for constraint
generation templates also have the advantage that we can adapt the
system to other specification languages by translation into
templates. The structure of the templates is close to the structure of
the typing rules of the specification language in
Section~\ref{sec:design--architecture}, but has no hard requirements
on the specification language other than being declarative.

\begin{definition}{Template}
  \todo[inline]{Complete this grammar and synchronize it with the
    Stratego source code} The syntax of templates in \gls{bnf}. The
  Stratego implementation appends to all constructors two underscores
  to avoid name collisions with target languages. This is necessary as
  the module system of Stratego is not strong enough to avoid those
  collisions. We omit these here for the sake of readability. The
  non-terminals Inputs, Outputs, Term and Error may contain arbitrary
  terms.
  \begin{grammar}
    <Template> ::= `Template' <Premisses> <Conjecture>

    <Conjecture> ::= `Conjecture' <Judg> <Name> <Pattern> <Outputs>

    <Premisses> ::= $\epsilon$ | <Premise> <Dependencies> <Premisses>

    <Premise> ::= `Lookup' <Ctx> <Inputs> <Outputs> <Error>
    \alt `Judgment' <Judg> <Inputs> <Binding> <Outputs> <Error>
    \alt `Eq' <Term> <Term> <Error>
    \alt `Neq' <Term> <Term> <Error>

    <Dependencies> ::= $\epsilon$ | <Judg> <Outputs> <Dependencies>

    <Name> ::= `Some' <String> | `None'

    <Judg> ::= <Int>
  \end{grammar}
\end{definition}

Before we describe the structure of templates in depth, we highlight
the conceptual differences between templates and typing rules.
Templates take advantage of the input/output tags of typing judgments
and context definitions by splitting everything up into an input and
output part. This will become handy in the constraint generation
phase. There we can see immediately which are the patterns to match
against the expressions and which are the output positions that we
compute. As described in the introduction to that chapter, we
normalize templates. That means, we add for each implicit equality in
the conclusion and premisses of typing rules an explicit
equality. Thus every variable occurs in each judgment only
once. Further we sort premisses by input/output position
dependencies. We describe and motivate the normalization process in
the remainder of the section. Note that the template optimization and
constraint generation phase take advantage of these normalizations and
therefore expect their inputs to be normalized.

Note: We transform all meta-variables of the specification into the
variables (\code|Var(name)|) that we use for constraint
generation. We describe the rename process in the next section.

\paragraph*{Premisses}
Premisses in templates have multiple shapes: Judgments, context
lookups, equalities and inequalities. A premise always has a list of
dependencies. This dependency list contains the number and the outputs
of the judgment the premise depends on. We define in the next
paragraph what it means for premise to have dependencies.

\begin{description}
\item[Judgments] correspond to the user defined judgments form the
  specification. They consist of the judgment number
  \refcallout{judgment:number} which refers to the position in the
  declaration section of the specification, the positions of the
  judgment marked as inputs \refcallout{judgment:inputs}, context
  modifications \refcallout{judgment:bind},
  \refcallout{judgment:reset}, \refcallout{judgment:identity}, the
  output positions of the judgments \refcallout{judgment:outputs} and
  error messages \refcallout{judgment:errors}.

  A context modification can either be an addition to a context
  \refcallout{judgment:bind} which consists of a context identifier
  (this identifier refers to the position in the declaration section
  of the specification), a list of inputs and a list of outputs. It
  can also be a context identity \refcallout{judgment:identity} which
  corresponds to the context meta-variables in the specification and
  do not modify the context and a reset operation
  \refcallout{judgment:reset} which resets the given context and
  corresponds to the empty context. Read to context modifications from
  right to left to obtain a valid context. A detail explanation of the
  semantics in our type checker will follow in
  Section~\ref{sec:constr-gener}.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Judgment(
        1 %*\callout{judgment:number}*)
      , [Var("X0")] %*\callout{judgment:inputs}*)
      , [ Binding(1, [Var("X1")], [Var("X2")]) %*\callout{judgment:bind}*)
        , Reset(1) %*\callout{judgment:reset}*)
        , Ctx(2) %*\callout{judgment:identity}*)
        ]
      , [Var("X3")] %*\callout{judgment:outputs}*)
      , Some([Error([Var("X0"), "has type", "{}"])]) %*\callout{judgment:errors}*)
      )
\end{lstlisting}
\label{ex:judgment}
\end{example}

In example~\ref{ex:judgment} we have judgment one that has only one
input position \code|Var("X0"| and one output position
\code|Var("X3")|. It leaves context two as it is, resets context one
and then adds the input/output pair \code|Var("X1")| and
\code|Var("X2")| to context one. In addition it has one error message.

\item[Context lookups] consist of the context number
  \refcallout{lookup:ctx}, of the input \refcallout{lookup:inputs} and
  of the output \refcallout{lookup:outputs} positions of the context
  lookup from the specification and of error messages
  \refcallout{lookup:errors}. We treat context lookups separately,
  because we generate them from the context declaration.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Lookup(
        1 %*\callout{lookup:ctx}*)
      , [Var("X0")] %*\callout{lookup:inputs}*)
      , [Var("X1")] %*\callout{lookup:outputs}*)
      , None() %*\callout{lookup:errors}*)
      )
\end{lstlisting}
\label{ex:lookup}
\end{example}

  In example~\ref{ex:lookup} we look up \code|Var("X0")| from
  context one and bind the result to \code|Var("X1)"|. This context
  lookup has no error messages attached.

\item[(In)equalities] are predefined judgments and therefore treated
  separately. They have two input positions and an potentially an
  error message. Apart from that they behave like normal judgments.

\begin{example}
\begin{lstlisting}[language=sltc]
Neq(Var("X0"), Var("X1"), None())
\end{lstlisting}
\label{ex:neq}
\end{example}

  In example~\ref{ex:neq} we compare \code|Var("X0")| and
  \code|Var("X1")| for inequality and provide no error message.
\end{description}

In some cases it is relevant in which order premisses we evaluate
premisses. We have not talked about evaluation yet, so assume we
evaluate premisses as functions. We provide terms for input positions
an retrieve terms for the output positions. If we look at
Example~\ref{ex:premise-dependencies} we see that rule \code|T-Tapp|
has two premisses. When we compare the premisses with the judgment
definitions, we see that \code|%x| occurs as an input of the first
premise and as within an output of the second premise but not at all
in the conclusion. If we want to evaluate the first premise we
have to find a term for \code|%x|, but that term is only provided by
the output of the second premise. Therefore we have to evaluate the
second premise first.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
judgments
TermBinding{I} "|" TypeBinding{I} "|-" Exp{I} ":" Type{O}.
Type{O} "= [" ID{I} "->" Type{I} "]" Type{I}.

rules
~U = [ %x -> ~S ] ~T
$C1 | $C2 |- ~e : all %x . ~T 
============================== T-Tapp
$C1 | $C2 |- ~e [ ~S ] : ~U
\end{lstlisting}
\label{ex:premise-dependencies}
\end{example}

We make those dependencies visible in the template language by
annotating each premise with a list of dependencies. Those
dependencies contain the number of the premise on which the premise
depends and the output of that premise. The outputs are redundant
information and only added to reduce indirections.
For the first premise in Example~\ref{ex:premise-dependencies} the
dependency would look like
\code|(1, [TAll(Var("X0"), Var("X1"))])|, where \code|1| refers to
the second premise, because we sort premisses of templates topological
according to the dependencies, as we will describe in the next
section.

\paragraph{Conclusion}
Conclusions contain the judgment identifier
\refcallout{conclusion:number}, the input positions of the judgment
\refcallout{conclusion:inputs}, the context modifications
\refcallout{conclusion:ctx} as well as the output positions of the
conclusion \refcallout{conclusion:outputs}.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Conclusion(
      3 %*\callout{conclusion:number}*)
    , ( [Var("X177")] %*\callout{conclusion:inputs}*)
      , [(2, [Var("X178")], []), Ctx(2)] %*\callout{conclusion:ctx}*)
      )
    , [] %*\callout{conclusion:outputs}*)
    )
\end{lstlisting}
\label{ex:conclusion}
\end{example}

Example~\ref{ex:conclusion} shows a conclusion that has judgment
number three, only one input position and the context pattern
specifies that there has to be at least one element in the second
context. In this example judgment three has no outputs.

Figure~\ref{fig:template-example} shows on the left side a simple
typing rules for variables in a $\lambda$-calculus style and on the
right side its representation as a template.

\subsubsection{Generation}
The Stratego rule \code|to-template| does the main part of the
template generation. It takes a rule from a specification and
transforms that into a template. The strategy \code|to-tempaltes| does
that iteratively for every rule in a specification. The first step in
the conversion is the elimination of implicit equalities in the
premisses and the conclusion.

We create for each implicit equality an explicit equality, by
collecting all variables that occur more than once in an input
position of a premise or conclusion. After that we create fresh names
for the collect variables and create premisses that state the equality
of the fresh meta-variables. Implicit equalities in premisses are not
transformed into explicit equalities if the meta-variables also occur
in the conclusion. These equalities are either ensured by explicit
equalities from the conclusion or if there are no implicit equalities
in the conclusion for this meta-variable, by the fact that this
variable occurs only once as a source an thus, cannot introduce
different values. If a meta-variable occurs more than twice we define
the equalities for the new variables transitively.

Example~\ref{ex:implicit-equalities} shows this for
a typing rule of the judgment

\begin{lstlisting}[language=sltc]
Type{O} "= [" ID{I} "->" Type{I} "]" Type{I}
\end{lstlisting}

which could model type substitution in a SystemF specification. On the
left of example~\ref{ex:implicit-equalities} you see the typing rule
with an implicit equality and on the right the transformed version
without the implicit equality.

\begin{example}{~}
\newline
  \begin{minipage}[b]{.45\linewidth}
    \begin{lstlisting}[language=sltc]
=====================
~S = [ %x -> ~S ] %x
\end{lstlisting}
  \end{minipage}
  \begin{minipage}[b]{.45\linewidth}
    \begin{lstlisting}[language=sltc]
%y = %z
=====================
~S = [ %y -> ~S ] %z
\end{lstlisting}
  \end{minipage}
\label{ex:implicit-equalities}
\end{example}

If there are error messages for implicit equalities, we associate
those error messages with the implicit equalities. Then we replace the
by the fresh meta-variables of the explicit equality and add the error
message as a normal error to the explicit equality.

\todo[inline]{Implicit equalities between inputs and outputs and
  between the contexts}

After this step, there are no implicit equalities left, i.e. all
meta-variables within a judgment are different. As a next step we
analyze the premisses of the typing rule for dependencies. A premise
depends on an other, if it uses meta-variables in input positions that
occur in an output position of an other premise and not as an input
position in the conclusion. As we need to supply the input positions
with concrete terms to check if a premise holds, we can evaluate a
dependency only if we evaluate first all its dependencies. In the
generation process we do two things, sort the premisses according to
their dependencies and annotate them with the output positions of the
dependencies, as described in the previous paragraph. The
implementation of this ordering is standard. First we collect all
premisses and their dependencies in a graph. Due to the nature of the
dependency it is more natural to create edges from a premise to the
premisses it depends on. Therefore the resulting dependency graph is a
transposed dependency graph. We sort this graph topologically with the
algorithm by Kahn~\cite{Kahn:1962:TSL:368996.369025}. The result is
the reversed order, as we used the transposed dependency
graph. Therefore we reverse the result of the topological sort. If we
encounter cycles in the dependency graph we report them and abort the
template generation.

After we have resolved implicit equalities and dependencies we begin
to generate templates. This process is, except for technical
subtleties, a straight forward rewriting of the rules from the
specification. 

\begin{figure}
  \centering
  \begin{minipage}{.35\linewidth}
\begin{lstlisting}[language=sltc]
%x : ~T in $C
============== T-var
$C |- %x : ~T
\end{lstlisting}
  \end{minipage}
  \begin{minipage}{.55\linewidth}
\begin{lstlisting}[language=sltc]
Template(
    Some("T-var")
  , [ ( Lookup(
          1
        , [Var("X52")]
        , [Var("X53")]
        , None()
        )
      , []
      )
    ]
  , Conclusion(
      1
    , ([Var(Var("X52"))], [Ctx(1)])
    , [Var("X53")]
    )
  )
\end{lstlisting}
  \end{minipage}
  \caption{Typing rule and template of T-Var}
  \label{fig:template-example}
\end{figure}
\subsection{Constraint Template Optimization}
\label{sec:constr-templ-optim}
In this section we describe and motivate the optimization strategies
we have used. The template optimization phase can do arbitrary
modifications, we focus here on optimization strategies that reduce
ambiguities between the templates.

Informally two templates are ambiguous if it is a priori not known
which (if any) of the templates we have to use to extend the
derivation tree to create a successful derivation. Therefore we have
to use the rules according to a heuristic and to backtrack if the
decision did not worked out. The goal of the optimization strategies
described in this section, is to rule out some of those ambiguities
before we even start to create derivations.

Before we introduce the optimization strategies, we define more
formally what an ambiguity is.

\begin{definition}
  A template is \textit{when-ambiguous} if there is an other
  template such that there is at least one term that matches the
  conclusion of both templates.
\label{def:when-ambiguous}
\end{definition}

Definition~\ref{def:when-ambiguous} describes the general case of an
ambiguity. If there is a template that has an syntactic overlap with
an other template, then there is an ambiguity. We call those
ambiguities when-ambiguity, because it is not clear when we have to
apply an ambiguous template. 

\begin{definition}
  A template is \textit{which-ambiguous} if there is an other template
  such that the set of terms matching the conclusion of both templates
  is equal.
\label{def:which-ambiguity}
\end{definition}

Definition~\ref{def:which-ambiguity} aims at a more specialized
ambiguities. Templates are when ambiguous if they match exactly the
same terms. There are just two (or more) templates that apply to
exactly the same terms. Therefore it is not the question \textit{when}
we have to apply a template, but only \textit{which} one we have to
apply. The distinction of those two kinds of ambiguities will help to
implement optimization strategies.

Before we describe the optimization strategies we implemented, we
extend the template language to make ambiguities explicit.

\begin{definition}
    The following grammar defines the extended template language.
    \begin{grammar}
    <Template> ::= $\dots$ | `Fork' <Templates>

    <Templates> ::= <Template> | <Template> <Templates>
    \end{grammar}
\end{definition}

The new constructor \code|Fork| has a list that contains at least one
template. The idea is that templates contained in \code|Fork|s are all
which-ambiguous to each other. We later use those groups of ambiguous
templates to decide at which points in the derivation we have to
decide which template we apply.

We look now into the optimization of which-ambiguities. First we
identify all which-ambiguities and create \code|Fork|s of them. We
implement using a strategy that groups arbitrary lists according to a
comparison strategy. Two templates are which-ambiguous if they have
the same judgment number and if the term pattern and context pattern
of the conclusion are equal modulo variables. Of the resulting groups
of templates we wrap all groups with more than one element into a
\code|Fork|.

We optimize forks containing which-ambiguities by checking whether a
template of a fork is subsumed by an other template of the same
fork. Template $t_1$ subsumes template $t_2$ if all premisses of $t_2$
imply at least one premise of $t_1$. This is sufficient, because the
conclusion of all templates within a fork matches the same terms.

In Example~\ref{ex:which-ambiguity} we have the depth and width
subtyping rules for records. Those two rules are which-ambiguous to
each other. Their conclusions contain the same judgment, have no
contexts and exactly the same term pattern.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
======== S-Refl
~T <: ~T

~T <: ~S
{ $R } <: { $U }
=============================== S-depth
{ %l : ~T $R } <: { %l : ~S $U }

~T = ~S
{ $R } <: { $U }
=============================== S-width
{ %l : ~T $R } <: { %l : ~S $U}
\end{lstlisting}
\label{ex:which-ambiguity}
\end{example}

We know that the subtyping relation \code|<:| is reflexive by the rule
\code|S-Refl|. Now we show that all premisses of \code|S-width| imply
at least one premise of \code|S-depth|. \code|~T = ~S| implies
\code|~T <: ~S| because the subtyping relation is reflexive and
\code|{ $R } <: { $U }| occurs verbatim as a premise of
\code|S-depth|. Therefore the depth subtyping rule subsumes the width
subtyping rule and we can remove the width subtyping rule.

We implement this check by testing for each template $t$ within a
fork, if there exists a template $t'$ such that

\begin{align}
  (p_1 \implies (q_1 \lor \dots \lor q_m)) \land \dots \land (p_n \implies
  (q_1 \lor \dots \lor q_m))
\label{formula:which-ambiguity}
\end{align}

holds, where $p_i$ are the premisses of $t$ and $q_i$ are the
premisses of $t'$. We verify the conjuncts in
Formula~\ref{formula:which-ambiguity} separately with the vampire
theorem prover. If vampire succeeds for all conjuncts we remove
template $t$. 

At the end of the optimization phase we sort the templates in the
remaining forks. Forks that have a specialized conclusion are before
forks with a general conclusion. This ordering has the advantage that
we can evaluate the templates in a fork from left to right, so that no
general template will catch all terms. More formally, we sort the
templates within a fork by $<$, which is defined as

\begin{align}
  t_1 < t_2 \iff m(t_1) \subseteq m(t_2)
\end{align}

where $m(t)$ computes the set of terms that match the conclusion of
$t$. We implement the comparison as a Stratego strategy and use the
quick sort implementation of the Stratego standard library. The
comparison strategy does the following. It checks whether the judgment
number is equal, which is always satisfied as we compare templates
within a fork. Then it checks whether the constructors of the term and
context pattern of left operand match the constructors of the term and
context pattern of the right operand modulo variable names.

\subsection{Constraint Generation}
\label{sec:constr-gener}
Constraint generation is the first phase of the generated type
checker. The inputs of this phase are constraint templates and the
expressions that should be type checked. The only input method for
expression we currently support is via the conjectures section of the
specification. However it should be straightforward to extend this
phase with support for e.g.\ \code|stdin|.

The constraint generation phase structured as follows. We initialize
contexts first and then generate constraints according to the programs
structure and the templates. After generating the constraints we
annotate whether the expression should have been well-typed or not.

Lets first look at the implementation of contexts. We store all
contexts in a hash table, with the context id as key. The contexts
itself are hash tables extended with a list that stores the insertion
order. Hash tables are a convenient data structure in the Stratego
standard library to store (multiple) data points at a key. They
reflect the intuition of the context declarations as cross products of
the terms corresponding to non-terminals. It is important to track the
insertion order, because some type systems (e.g.\ ordered type
systems) might rely on the ordering within contexts.

We decided to use hashtables instead of normal key-value lists for the
context representation to reduce the lookup time in realistic programs
which declare identifiers much less then they refer to them. However
we do not have experimental evidence if this speeds up type checking,
because we do not have a key-value list implementation of contexts.

However implementing contexts using extended hash tables forced us to
separate context operations from normal inputs. This creates on the
one hand more exceptional cases (e.g.\ the matching complex matching
algorithms described in Section~\ref{sec:constr-templ-optim}) it leads
on the other hand to a modular context implementation with the
potential to exchange the implementation easily.

Before can explain how we generate constraints, we have to define the
constraint language.

\begin{definition}{Constraint Language}
  \begin{grammar}
    <Constraint> ::= `CFail' <Error>
    \alt `CEq' <Term> <Term> <Error>
    \alt `CNeq' <Term> <Term> <Error>
  \end{grammar}
\end{definition}

We annotate all constraints with error messages. These error messages
are either generated during the constraints generation or passed
through from the specification. The constraint solver shows the error
messages if it cannot solve a constraint. There are three types of
constraints. The constraint \code|CFail| corresponds to false and
cannot be solved. Further \code|CEq| and \code|CNeq| are equality
respectively inequality constraints.

As we read the program expressions from the conjecture section of the
specification, we already have the initial contexts, the judgment
number and we can tell which are input and output positions. If we
would read only the program expression (e.g.\ from \code|stdin|)
information about the initial contexts, the judgment number and the
output positions need to be passed separately. Every conjecture has a
fresh context store, initialized with the initial contexts provided in
the conjecture.

We have divided the main logic of constraint generation into three
Stratego strategies: \code|generate| selects the template matching the
current term, \code|generate'| applies the current term to the
conclusion of the selected template and \code|execute| evaluates the
premisses of the template. All three strategies return a tuple of the
computed outputs and the generated constraints. We wrap the computed
outputs into \code|Option| to model the absence of outputs in cases of
errors.

After initializing the contexts we call the strategy \code|generate|
with the judgment number and the inputs of the conjecture. We also
pass the expected outputs and set the parameter \code|init| to
\code|true|. This parameter is \code|false| for all other cases except
the initial call to \code|generate| and used to generate an equality
constraint for the expected and actual outputs.

Now \code|generate| calls \code|find-match| to find a template whose
conclusion matches the inputs, judgment number and the current state
of the contexts. First \code|find-match| filters all templates with the
correct judgment number and tests only those templates for matches. In
case of \code|Fork| only those templates are retained that match. For
all other templates \code|find-match| checks whether the constructors
of the term pattern in the conclusion and of the input term
match. Those match, if they have the same constructors on all levels,
where the term pattern can have variables for whole levels. In
addition the context pattern of the conclusion has to reflect the
current state of the contexts. The context pattern reflects the state
of the contexts if it can be applied from left to right to the context
without failures.

\code|find-match| safely takes the first template that matches,
because we have ensured in Section~\ref{sec:constr-templ-optim} that
there is only one template that matches. If no template matches, we
return \code|None| for the outputs and the singelton list containing
the constraint that always fails, with an appropriate error
message. If \code|find-match| succeeds to find a template it calls
\code|generate'| with that template.

The rule \code|generate'| now evaluates the selected template
according to the given input. In \code|generate'| we use patterns to
access specific elements of terms. The corresponding element to the
input term is the term pattern of the templates conclusion. We update
the terms and patterns if we want to add an other term and pattern to
the scope. The patterns and terms are later used to instantiate
variables in premisses or error messages.

If the selected rule is no fork, the evaluation works as follows. In
correspondence to the bindings in the context pattern of the
conclusion, we pop all terms from the contexts and bring them into
scope. Also if a variable occurs in the inputs of a premise but not in
the inputs of the conclusion nor in the outputs of other premisses but
int the outputs of the conclusion, then we bring it into scope with
the expected outputs. This allows to deal with typing rules that have
free variables in their premisses as for instance in the subsumption
rule for subtyping.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
$C |- ~e : ~S
~S <: ~T
============= T-Sub
$C |- ~e : ~T
\end{lstlisting}
\label{ex:subsumption}
\end{example}

Example~\ref{ex:subsumption} shows the subsumption rule from
\todo{Cite}. In the rule \code|~T| occurs free in the second
premise. Binding it to the expected output of \code|~T| allows to
still evaluate this premise.

Now we have to replace all variables introduced by the selected
template with fresh variables, otherwise applying a template twice
would lead to collisions. All variables introduces in the previous
phases have variables names have prefix different from
\code|Y|. Therefore we replace all variables that do not have the
prefix \code|Y| with a fresh variable with the prefix
\code|Y|. Additionally this allows to verify visually to check whether
all variables are fresh.

Now we evaluate the premisses of the template. A key element in the
evaluation is the instantiation of the variables in the premise
patterns according to the conclusion pattern and input term, because
we need input terms to recursively call \code|generate| on the
premisses or to create solvable (in-)equality constraints.

We initialize variables in inputs of a judgment using a term and a
pattern which describes the structure of the term. To instantiate a
variable we search it in the pattern, by walking through the abstract
syntax tree of the pattern and record the path to the variable. As
every variable is distinct since we resolved every implicit equality i
the templates and have introduced no new implicit equality we can take
the first and only occurrence of the variable. If we find a path to
that variable, we use it to retrieve terms from the corresponding
term, by walking along the path and fetching the node at its end. We
ensure that the pattern and term always have the same structure,
otherwise we would retrieve false positives.

As the premisses were topologically sorted as described in
Section~\ref{sec:constraint-templates} we can evaluate them in the
given order. However, to ensure that the terms of all dependencies are
available during evaluation, we have to accumulate the outputs of the
evaluated premisses and add those to the patterns and terms used for
the instantiation.

The strategy \code|execute| does the evaluation of the premisses. We
call \code|execute| for each premise with a copy of the contexts to
ensure that one premise cannot pollute the contexts of an other
premise. We have implemented a safe version of \code|hashtable-copy|
to ensure that after evaluation of the premise all copies are
destroyed.

We now describe what \code|execute| does for the different types of
premisses.

\begin{description}
\item[Lookup:] The inputs of the lookup are instantiated, then the
  resulting term is looked up in the corresponding context. If the
  lookup succeeds the result is returned as an output, together with a
  constraint set that contains equality constraint between the output
  pattern and the looked up output. Those constraints are annotated
  with the corresponding error message, which is instantiated and in
  which the hole (\code|{}|) is replaced by the output variables. If
  the lookup fails \code|None| is return as output together with the
  \code|CFail| constraint and an appropriate error message.
\item[(In)equality:] Equalities and inequalities are initialized and
  returned as constraints, together with the output \code|None| as
  they have no output positions.
\item[Judgment:] If the premise is a judgment it is first
  instantiated. Then we call \code|generate| on the resulting input
  term with an version of the store that has been updated according to
  the context pattern of the judgment. In addition we instantiate the
  expected outputs of the judgment to make the binding of free
  variables in premisses more precise. After the call to
  \code|generate| returns we generate equality constraints for the
  bindings in the context pattern of the premise and generate equality
  constraints between the output pattern and the computed output, with
  corresponding instantiated error messages. The hole (\code|{}|) in
  the error messages is here also replaced by the output variables.
\end{description}

In the case \code|generate'| encounters a fork it evaluates all
templates contained in the fork using \code|generate'|. It tries to
solve the resulting constraint set and returns the outputs of the
first evaluation that succeeds. If no templates can be evaluated to an
solvable constraint set we return the constraint that always fails
with an appropriate error message. This procedure ensures, because of
the ordering of forks in Section~\ref{sec:constr-templ-optim}, that
potential rules that produce solvable constraint sets but do not make
real progress are deferred to the end.

\subsection{Constraint Solving}
\label{sec:constraint-solving}
Constraint solving is the last phase of the type checker. As the
constraint language is with only three constructs simple, the
algorithm to solve a constraint set is simple as well.

We use unification to solve the constraint sets. Precisely we use a
variant of Robinson unificiation \todo{Citation}. During the
unification we compute a \gls{mgu} to instantiate the variables in the
outputs and (in case of ill-typed programs) in the error messages that
we collect every time a constraint cannot be solved.

During unification we ensure that certain kind of malformed constraint
sets do not lead to infinite loops in the unification. We abort
unification if there are only inequalities left that contain at least
one variable. As inequality is not transitive, we can never solve
those constraint sets.
\section{Performance}
\label{sec:performance}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report"
%%% End: 
