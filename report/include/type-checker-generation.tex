\chapter{Type Checker Generation}
\todo[inline]{Terminology: Type Checker vs. Type Inference}
\section{Goals}
This section briefly describes and motivates the design and goals of
the type checker generator.

The first goal is to produce fast type checkers, even if the type
system specification is not geared towards performance. Mainly this
means to try to deal with non-syntax directed typing rules without
backtracking. The motivation for this is that non-syntax directed
typing rules are often more readable and changes have mainly local
effects.

The second goal is to design a modular type checker generator. A type
checker generator that can be easily adapted and that facilitates the
exchange of components. This modularity is desirable because it
increases the reusability and makes it possible to combine previously
unrelated projects.

The third goal is to generate type checkers that emit readable error
messages if a program is not well-typed. This is essential to make the
generated type checker usable in any way.
\section{Architecture}
The type checker generator has two phases: Template generation and
template optimization. The template generation phase transforms the
type system specification with minor modifications into templates. A
template is a different representation for a typing rule, that is
better suited for type checking. We introduce templates in detail in
Section~\ref{sec:constraint-templates}. The template optimization
phase optimizes checks which optimizations apply to those templates
and applies them. The optimizations aim to reduce the amount of
non-determinism in the type system and therefore reduce the amount of
backtracking in the type checker. The final product after those two
phases is a file that contains the optimized templates.

Instead of generating a type checker directly from the specification,
we implement a generic constraint-based type checker that takes
templates as input. This generic type checker has two phases:
Constraint generation and constraint solving. The constraint
generation phase has the templates and the expression that shall be
type check as input. We then build a derivation tree according to the
expression by pattern matching the conclusion of the
templates. Building and traversing of the derivation tree emits
constraints. The constraint solving phase then tries unify the emitted
constraints. If that succeeds it reports the result otherwise it
reports the errors that occurred during unification.

Figure~\ref{fig:phases} shows the phases and their
relationships. Nodes represent phases and arrows express that data flows
from one node to an other. Labels on arrows describe the data format.

The four phases correspond to modules or tools. Each phase has a
well-defined interface, therefore the implementation can be exchanged
freely. This makes it possible to use different constraint solvers,
constraint generators or template optimizers.

\begin{figure}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,align=center,node distance=2cm,
  thick,main node/.style={rectangle,fill=blue!20,draw,font=\small\bfseries}]

  \node[main node] (1) {Template Generation};
  \node[main node] (2) [right=3cm of 1] {Template Optimization};
  \node[main node] (3) [below of=2] {Constraint Generation};
  \node[main node] (4) [below of=1] {Constraint Solving};
  \coordinate [below right of=3] (5);
  \coordinate [above of=1] (6);

  \path[every node/.style={font=\small}]
    (1) edge node [right, below] {Templates} (2)
    (2) edge node [right] {Extended Templates} (3)
    (5) edge node [right] {Program} (3)
    (3) edge node [right, below] {Constraints} (4)
    (6) edge node [right] {Specification} (1);
\end{tikzpicture}
\caption{Phases of the type checker generator}
\label{fig:phases}
\end{figure}
\section{Implementation}
\label{sec:implementation}
The following sections describe the implementation of the type checker
generator, one section per phase.

\subsection{Template Generation}
\label{sec:constraint-templates}
The first phase translates type system specifications into
templates. This phase is not just a simple translation from a human
readable representation into a representation suitable for programs,
but also normalizes the resulting templates. Normalization comprises
the elimination of implicit equalities and resolves dependencies
between premisses. All following phases assume normalized templates,
which simplifies parts of them.

\subsubsection{Templates}
A template is an intermediate representation of a typing rule that is
more suitable for the constraint generation process and defined as
following.

Templates serve as the input format for the constraint generation
phase of the type checker. Besides being better suited for constraint
generation templates also have the advantage that we can adapt the
system to other specification languages by translation into
templates. The structure of the templates is close to the structure of
the typing rules of the specification language in
Section~\ref{sec:design--architecture}, but has no hard requirements
on the specification language other than being declarative.

\begin{definition}{Template}
  \todo[inline]{Complete this grammar and synchronize it with the
    Stratego source code} The syntax of templates in \gls{bnf}. The
  Stratego implementation appends to all constructors two underscores
  to avoid name collisions with target languages. This is necessary as
  the module system of Stratego is not strong enough to avoid those
  collisions. We omit these here for the sake of readability. The
  non-terminals Inputs, Outputs, Term and Error may contain arbitrary
  terms.
  \begin{grammar}
    <Template> ::= `Template' <Premisses> <Conjecture>

    <Conjecture> ::= `Conjecture' <Judg> <Name> <Pattern> <Outputs>

    <Premisses> ::= $\epsilon$ | <Premise> <Dependencies> <Premisses>

    <Premise> ::= `Lookup' <Ctx> <Inputs> <Outputs> <Error>
    \alt `Judgment' <Judg> <Inputs> <Binding> <Outputs> <Error>
    \alt `Eq' <Term> <Term> <Error>
    \alt `Neq' <Term> <Term> <Error>

    <Dependencies> ::= $\epsilon$ | <Judg> <Outputs> <Dependencies>

    <Name> ::= `Some' <String> | `None'

    <Judg> ::= <Int>
  \end{grammar}
\end{definition}

Before we describe the structure of templates in depth, we highlight
the conceptual differences between templates and typing rules.
Templates take advantage of the input/output tags of typing judgments
and context definitions by splitting everything up into an input and
output part. This will become handy in the constraint generation
phase. There we can see immediately which are the patterns to match
against the expressions and which are the output positions that we
compute. As described in the introduction to that chapter, we
normalize templates. That means, we add for each implicit equality in
the conclusion and premisses of typing rules an explicit
equality. Thus every variable occurs in each judgment only
once. Further we sort premisses by input/output position
dependencies. We describe and motivate the normalization process in
the remainder of the section. Note that the template optimization and
constraint generation phase take advantage of these normalizations and
therefore expect their inputs to be normalized.

Note: We transform all meta-variables of the specification into the
variables (\verb|Var(name)|) that we use for constraint
generation. We describe the rename process in the next section.

\paragraph*{Premisses}
Premisses in templates have multiple shapes: Judgments, context
lookups, equalities and inequalities. A premise always has a list of
dependencies. This dependency list contains the number and the outputs
of the judgment the premise depends on. We define in the next
paragraph what it means for premise to have dependencies.

\begin{description}
\item[Judgments] correspond to the user defined judgments form the
  specification. They consist of the judgment number
  \refcallout{judgment:number} which refers to the position in the
  declaration section of the specification, the positions of the
  judgment marked as inputs \refcallout{judgment:inputs}, context
  modifications \refcallout{judgment:bind},
  \refcallout{judgment:reset}, \refcallout{judgment:identity}, the
  output positions of the judgments \refcallout{judgment:outputs} and
  error messages \refcallout{judgment:errors}.

  A context modification can either be an addition to a context
  \refcallout{judgment:bind} which consists of a context identifier
  (this identifier refers to the position in the declaration section
  of the specification), a list of inputs and a list of outputs. It
  can also be a context identity \refcallout{judgment:identity} which
  corresponds to the context meta-variables in the specification and
  do not modify the context and a reset operation
  \refcallout{judgment:reset} which resets the given context and
  corresponds to the empty context. Read to context modifications from
  right to left to obtain a valid context. A detail explanation of the
  semantics in our type checker will follow in
  Section~\ref{sec:constr-gener}.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Judgment(
        1 %*\callout{judgment:number}*)
      , [Var("X0")] %*\callout{judgment:inputs}*)
      , [ Binding(1, [Var("X1")], [Var("X2")]) %*\callout{judgment:bind}*)
        , Reset(1) %*\callout{judgment:reset}*)
        , Ctx(2) %*\callout{judgment:identity}*)
        ]
      , [Var("X3")] %*\callout{judgment:outputs}*)
      , Some([Error([Var("X0"), "has type", "{}"])]) %*\callout{judgment:errors}*)
      )
\end{lstlisting}
\label{ex:judgment}
\end{example}

In example~\ref{ex:judgment} we have judgment one that has only one
input position \verb|Var("X0"| and one output position
\verb|Var("X3")|. It leaves context two as it is, resets context one
and then adds the input/output pair \verb|Var("X1")| and
\verb|Var("X2")| to context one. In addition it has one error message.

\item[Context lookups] consist of the context number
  \refcallout{lookup:ctx}, of the input \refcallout{lookup:inputs} and
  of the output \refcallout{lookup:outputs} positions of the context
  lookup from the specification and of error messages
  \refcallout{lookup:errors}. We treat context lookups separately,
  because we generate them from the context declaration.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Lookup(
        1 %*\callout{lookup:ctx}*)
      , [Var("X0")] %*\callout{lookup:inputs}*)
      , [Var("X1")] %*\callout{lookup:outputs}*)
      , None() %*\callout{lookup:errors}*)
      )
\end{lstlisting}
\label{ex:lookup}
\end{example}

  In example~\ref{ex:lookup} we look up \verb|Var("X0")| from
  context one and bind the result to \verb|Var("X1)"|. This context
  lookup has no error messages attached.

\item[(In)equalities] are predefined judgments and therefore treated
  separately. They have two input positions and an potentially an
  error message. Apart from that they behave like normal judgments.

\begin{example}
\begin{lstlisting}[language=sltc]
Neq(Var("X0"), Var("X1"), None())
\end{lstlisting}
\label{ex:neq}
\end{example}

  In example~\ref{ex:neq} we compare \verb|Var("X0")| and
  \verb|Var("X1")| for inequality and provide no error message.
\end{description}

In some cases it is relevant in which order premisses we evaluate
premisses. We have not talked about evaluation yet, so assume we
evaluate premisses as functions. We provide terms for input positions
an retrieve terms for the output positions. If we look at
Example~\ref{ex:premise-dependencies} we see that rule \verb|T-Tapp|
has two premisses. When we compare the premisses with the judgment
definitions, we see that \verb|%x| occurs as an input of the first
premise and as within an output of the second premise but not at all
in the conclusion. If we want to evaluate the first premise we
have to find a term for \verb|%x|, but that term is only provided by
the output of the second premise. Therefore we have to evaluate the
second premise first.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
judgments
TermBinding{I} "|" TypeBinding{I} "|-" Exp{I} ":" Type{O}.
Type{O} "= [" ID{I} "->" Type{I} "]" Type{I}.

rules
~U = [ %x -> ~S ] ~T
$C1 | $C2 |- ~e : all %x . ~T 
============================== T-Tapp
$C1 | $C2 |- ~e [ ~S ] : ~U
\end{lstlisting}
\label{ex:premise-dependencies}
\end{example}

We make those dependencies visible in the template language by
annotating each premise with a list of dependencies. Those
dependencies contain the number of the premise on which the premise
depends and the output of that premise. The outputs are redundant
information and only added to reduce indirections.
For the first premise in Example~\ref{ex:premise-dependencies} the
dependency would look like
\verb|(1, [TAll(Var("X0"), Var("X1"))])|, where \verb|1| refers to
the second premise, because we sort premisses of templates topological
according to the dependencies, as we will describe in the next
section.

\paragraph{Conclusion}
Conclusions contain the judgment identifier
\refcallout{conclusion:number}, the input positions of the judgment
\refcallout{conclusion:inputs}, the context modifications
\refcallout{conclusion:ctx} as well as the output positions of the
conclusion \refcallout{conclusion:outputs}.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Conclusion(
      3 %*\callout{conclusion:number}*)
    , ( [Var("X177")] %*\callout{conclusion:inputs}*)
      , [(2, [Var("X178")], []), Ctx(2)] %*\callout{conclusion:ctx}*)
      )
    , [] %*\callout{conclusion:outputs}*)
    )
\end{lstlisting}
\label{ex:conclusion}
\end{example}

Example~\ref{ex:conclusion} shows a conclusion that has judgment
number three, only one input position and the context pattern
specifies that there has to be at least one element in the second
context. In this example judgment three has no outputs.

Figure~\ref{fig:template-example} shows on the left side a simple
typing rules for variables in a $\lambda$-calculus style and on the
right side its representation as a template.

\subsubsection{Generation}
The Stratego rule \verb|to-template| does the main part of the
template generation. It takes a rule from a specification and
transforms that into a template. The strategy \verb|to-tempaltes| does
that iteratively for every rule in a specification. The first step in
the conversion is the elimination of implicit equalities in the
premisses and the conclusion.

We create for each implicit equality an explicit equality, by
collecting all variables that occur more than once in an input
position of a premise or conclusion. After that we create fresh names
for the collect variables and create premisses that state the equality
of the fresh meta-variables. Implicit equalities in premisses are not
transformed into explicit equalities if the meta-variables also occur
in the conclusion. These equalities are either ensured by explicit
equalities from the conclusion or if there are no implicit equalities
in the conclusion for this meta-variable, by the fact that this
variable occurs only once as a source an thus, cannot introduce
different values. If a meta-variable occurs more than twice we define
the equalities for the new variables transitively.

Example~\ref{ex:implicit-equalities} shows this for
a typing rule of the judgment

\begin{lstlisting}[language=sltc]
Type{O} "= [" ID{I} "->" Type{I} "]" Type{I}
\end{lstlisting}

which could model type substitution in a SystemF specification. On the
left of example~\ref{ex:implicit-equalities} you see the typing rule
with an implicit equality and on the right the transformed version
without the implicit equality.

\begin{example}{~}
\newline
  \begin{minipage}[b]{.45\linewidth}
    \begin{lstlisting}[language=sltc]
=====================
~S = [ %x -> ~S ] %x
\end{lstlisting}
  \end{minipage}
  \begin{minipage}[b]{.45\linewidth}
    \begin{lstlisting}[language=sltc]
%y = %z
=====================
~S = [ %y -> ~S ] %z
\end{lstlisting}
  \end{minipage}
\label{ex:implicit-equalities}
\end{example}

If there are error messages for implicit equalities, we associate
those error messages with the implicit equalities. Then we replace the
by the fresh meta-variables of the explicit equality and add the error
message as a normal error to the explicit equality.

\todo[inline]{Implicit equalities between inputs and outputs and
  between the contexts}

After this step, there are no implicit equalities left, i.e. all
meta-variables within a judgment are different. As a next step we
analyze the premisses of the typing rule for dependencies. A premise
depends on an other, if it uses meta-variables in input positions that
occur in an output position of an other premise and not as an input
position in the conclusion. As we need to supply the input positions
with concrete terms to check if a premise holds, we can evaluate a
dependency only if we evaluate first all its dependencies. In the
generation process we do two things, sort the premisses according to
their dependencies and annotate them with the output positions of the
dependencies, as described in the previous paragraph. The
implementation of this ordering is standard. First we collect all
premisses and their dependencies in a graph. Due to the nature of the
dependency it is more natural to create edges from a premise to the
premisses it depends on. Therefore the resulting dependency graph is a
transposed dependency graph. We sort this graph topologically with the
algorithm by Kahn~\cite{Kahn:1962:TSL:368996.369025}. The result is
the reversed order, as we used the transposed dependency
graph. Therefore we reverse the result of the topological sort. If we
encounter cycles in the dependency graph we report them and abort the
template generation.

After we have resolved implicit equalities and dependencies we begin
to generate templates. This process is, except for technical
subtleties, a straight forward rewriting of the rules from the
specification. 

\begin{figure}
  \centering
  \begin{minipage}{.35\linewidth}
\begin{lstlisting}[language=sltc]
%x : ~T in $C
============== T-var
$C |- %x : ~T
\end{lstlisting}
  \end{minipage}
  \begin{minipage}{.55\linewidth}
\begin{lstlisting}[language=sltc]
Template(
    Some("T-var")
  , [ ( Lookup(
          1
        , [Var("X52")]
        , [Var("X53")]
        , None()
        )
      , []
      )
    ]
  , Conclusion(
      1
    , ([Var(Var("X52"))], [Ctx(1)])
    , [Var("X53")]
    )
  )
\end{lstlisting}
  \end{minipage}
  \caption{Typing rule and template of T-Var}
  \label{fig:template-example}
\end{figure}
\subsection{Constraint Template Optimization}
\label{sec:constr-templ-optim}
In this section we describe and motivate the optimization strategies
we have used. The template optimization phase can do arbitrary
modifications, we focus here on optimization strategies that reduce
ambiguities between the templates.

Informally two templates are ambiguous if it is a priori not known
which (if any) of the templates we have to use to extend the
derivation tree to create a successful derivation. Therefore we have
to use the rules according to a heuristic and to backtrack if the
decision did not worked out. The goal of the optimization strategies
described in this section, is to rule out some of those ambiguities
before we even start to create derivations.

Before we introduce the optimization strategies, we define more
formally what an ambiguity is.

\begin{definition}
  A template is \textit{when-ambiguous} if there is an other
  template such that there is at least one term that matches the
  conclusion of both templates.
\label{def:when-ambiguous}
\end{definition}

Definition~\ref{def:when-ambiguous} describes the general case of an
ambiguity. If there is a template that has an syntactic overlap with
an other template, then there is an ambiguity. We call those
ambiguities when-ambiguity, because it is not clear when we have to
apply an ambiguous template. 

\begin{definition}
  A template is \textit{which-ambiguous} if there is an other template
  such that the set of terms matching the conclusion of both templates
  is equal.
\label{def:which-ambiguity}
\end{definition}

Definition~\ref{def:which-ambiguity} aims at a more specialized
ambiguities. Templates are when ambiguous if they match exactly the
same terms. There are just two (or more) templates that apply to
exactly the same terms. Therefore it is not the question \textit{when}
we have to apply a template, but only \textit{which} one we have to
apply. The distinction of those two kinds of ambiguities will help to
implement optimization strategies.

\subsection{Constraint Generation}
\label{sec:constr-gener}
Constraint generation is the first phase of the type checker. The
inputs of this phase are constraint templates and the expressions that
should be type checked. Currently those expressions are defined in the
conjecture section of the type system specification. \todo{Change
  this, at least for benchmarking it is nescessary to pass programs
  via stdin}

The constraint generation phase structured as follows. First, contexts
are intialized, then constraint are generated according to the
programs structure and the templates and at the end a constraint is
added that binds the infered type with the acutal type.

Lets first look on the implementation of the contexts. Contexts are
stored in a hashtable, with the context id as key. This implies that
at every point in the derivation, there is only one instance of each
context. This assumption is true for all type systems we have
investigated. Further a context is defined as a hashtable which keeps
track of the insertion order of the elements. The insertion order is
important for type systems that rely on the ordering of contexts
\todo{Example}. Keys of the hashtable are the input positions of the
context and values are the output positions. As we use a hashtable
rather than a hashmap it is also possible to store multiple values at
a single key. We decided to use hashtables instead of normal key-value
lists for the context representation to reduce the lookup time in
large programs with many identifiers. However we do not have
experimental evidence on this, because we do not have a key-value list
implementation of contexts.

However implementing contexts using extended hashtables forced us to
separate context operations from normal inputs. This creates on the
one hand many exceptional cases (e.g. the matching complex matching
algorithms described in section~\ref{sec:constr-templ-optim}) it lead
on the other hand to a modular context implementation with the
potential to exchange the implementation easily.

We now define the constraint language. It is a simple language
consisting of three constraints.

\begin{definition}{Constraint Language}
  \begin{grammar}
    <Constraint> ::= `CFail' <Error>
    \alt `CEq' <Term> <Term> <Error>
    \alt `CNeq' <Term> <Term> <Error>
  \end{grammar}
\end{definition}

\verb|CFail| is the constraint that cannot be unified and \verb|CEq|
and \verb|CNeq| are ordinary equality and inequality
constraints. \verb|Term| and \verb|Error| are arbitrary terms.

The program expression that is passed to the constraint generator is
wrapped in the desired typing judgment with initial contexts and
potentially with expected results. Every conjecture is provided with
an empty context-store. The context in this store are intialized with
the context information in the judgment.

After the context is intialized all terms at input positions of the
judgment are passed into the \verb|generate| rule, together with the
judgment number. Now the templates are searched for a template that has the
correct judgment identifier in its conclusion, matching input
positions and a context description that reflects the current state in
the store. The first template that matches is taken as we have ensured
in section~\ref{sec:constr-templ-optim} that there is only one such
rule. If no template matches those criteria the constraint that always
fails is return with an appropriate error message. In general
\verb|generate| returns a pair of the output and a constraint set,
where the output is optional. \todo{It is not so clear where the
  output comes from}

The rule \verb|generate'| evaluates the selected template according to
the given input. In case of \verb|Template__| the evaluation works as
follows. At first the contexts are updated according to the context
modifications in the conclusion. This means the description of the
context modifications is read from left to right. On a context bind,
the first element of the corresponding context is popped from the
context. To be able to access this element, it is appended to the
input. Context variables correspond to identity and \verb|Reset__|
clears the whole context, without making any element available.

Next all variables in the selected template are replaced by fresh
ones. This is also indicated visually, as all variables in the
template generation phase start with \verb|X| and all variables
generated in the constraint generation phase with \verb|Y|. This
renaming ensures that now collisions occur if a template is used more
than once.

Now that all variables are fresh, the context is modified in
accordance to the premisses the premisses of the template are
evaluated. A key element in the evaluation is the instantiation of the
variables in the premise patterns according to the conclusion pattern
and input term, because we need input terms to call \verb|generate| on
the premisses.

Variables in inputs of a judgment are initialized using a term and a
pattern which describes the structure of the term. Now every variable
in the inputs is searched in the pattern, by walking through the
abstract syntax tree of the pattern and recording the path to the
variable. As there are no implicit equalities in the templates we can
take the first and only occurrence of the variable. After a path was
found for every variable that occurs in the pattern, those paths are
used to retrieve terms from the corresponding term, by walking along
the path and fetching the node at its end. The variables in the inputs
are now replaced by the fetched nodes.

As the premisses were topologically sorted as described in
Section~\ref{sec:constraint-templates} they are evaluated in the
correct order. However, to ensure that the terms of all dependencies
are available during evaluation, we accumulate the outputs of the
evaluated premisses and add those to the pattern and term used for the
instantiation.

\begin{description}
\item[Lookup:] The inputs are instantiated, then the resulting term is
  looked up in the context. If the lookup succeeds the result is
  returned, together with an empty constraint set. Otherwise, no
  output is returned together with the \verb|CFail| constraint.
\item[(In)equality:] Equalities and inequalities are initialized and
  return as constraints.
\item[Judgment:] Judgments are instantiated, the store is updated
  according to the context bindings and \verb|generate| is called on
  the resulting terms. In addition constraints for the context
  bindings are generated. \todo{Examples}
\end{description}

For the evaluation of every judgment a copy of the store is passed, to
ensure that everything that is bound is released at the correct point
in time.



\subsection{Constraint Solving}
\label{sec:constraint-solving}
\todo[inline]{What else should be contained in this section?}
Constraint solving is the last phase of the type checker. As the
constraint language is with only three constructs simple, the
algorithm to solve a constraint set is simple as well.

Unification is used to solve the constraint set. Precisely we use a
variant of Robinson unificiation \todo{Citation}. During the
unification an most general unifier (mgu) is computed to instantiate
the variables in the outputs and (in case of not well-typed programs)
in the error messages.
\section{Performance}
\label{sec:performance}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report"
%%% End: 
