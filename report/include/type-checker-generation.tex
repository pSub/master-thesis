\chapter{Type Checker Generation}
\section{Goals}
In this section we briefly describe and motivate the design and goals
of the type checker generator.

The first goal is to generate type checkers from high level type
system specifications that are not geared to type checking. Mainly
this means to try to deal with non-syntax directed typing rules
without backtracking. The motivation for this is that non-syntax
directed typing rules are often more readable and that changes have
mainly local effects. 

The second goal is to design a modular type checker generator,
particularly one that can be easily adapted and that facilitates the
exchange of components. This modularity is desirable because it
increases the reusability and makes it possible to combine previously
unrelated projects.

The third goal is to generate type checkers that emit readable error
messages if a program is not well-typed. This is essential to make the
generated type checker usable in production in any way.
\section{Architecture}
The type checker generator has two phases: Template generation and
template optimization. The template generation phase transforms the
type system specification with modifications into templates. A
template is a different representation for a typing rule that is
better suited for type checking. We introduce templates in detail in
Section~\ref{sec:constraint-templates}. The template optimization
phase checks which optimizations apply to the generated templates and
applies them. The optimizations aim to reduce the amount of
non-determinism in the type system and therefore reduce the amount of
backtracking in the type checker. The final product after those two
phases is a file that contains the optimized templates.

The template optimization phase is the key part of the type checker
generator. It is the link between the type checker generator on the
one hand and the formula generation and automated theorem provers on
the other hand. We generate from a single type system specification a
first-order formula representation suitable for theorem proving and a
template representation suitable for constraint generation. In the
optimization phase we combine them by using the automated theorem
prover to check if optimizations are applicable to the templates.

Instead of generating a type checker directly from the specification,
we implement a generic constraint-based type checker that takes
templates as input. This generic type checker has two phases:
Constraint generation and constraint solving. The constraint
generation phase takes the templates and the expression that shall be
type checked as input. We then build a derivation tree according to
the expression by pattern matching the conclusion of the
templates. The building and traversing of the derivation tree emits
constraints. In the constraint solving phase we then try to unify the
emitted constraints. If that succeeds it reports the result otherwise
it reports the errors that occurred during unification.

Figure~\ref{fig:phases} shows the phases and their
relationships. Nodes represent phases and arrows express that data
flows from one node to another. Labels on arrows describe the data
format.

The four phases correspond to modules or tools. Each phase has a
well-defined interface, therefore the implementation can be exchanged
freely. This facilitates the use of different constraint solvers,
constraint generators or template optimizers.

\begin{figure}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,align=center,node distance=2cm,
  thick,main node/.style={rectangle,fill=blue!20,draw,font=\small\bfseries}]

  \node[main node] (1) {Template Generation};
  \node[main node] (2) [right=3cm of 1] {Template Optimization};
  \node[main node] (3) [below of=2] {Constraint Generation};
  \node[main node] (4) [below of=1] {Constraint Solving};
  \coordinate [below right of=3] (5);
  \coordinate [above of=1] (6);

  \path[every node/.style={font=\small}]
    (1) edge node [right, below] {Templates} (2)
    (2) edge node [right] {Extended Templates} (3)
    (5) edge node [right] {Program} (3)
    (3) edge node [right, below] {Constraints} (4)
    (6) edge node [right] {Specification} (1);
\end{tikzpicture}
\caption{Phases of the type checker generator}
\label{fig:phases}
\end{figure}

The following sections describe the implementation of the type checker
generator. Each section focuses on one of the phases.

\section{Template Generation}
\label{sec:constraint-templates}
The first phase translates type system specifications into
templates. This phase is not just a simple translation from a human
readable representation into a representation suitable for programs,
but also normalizes the resulting templates. Normalization comprises
the elimination of implicit equalities and resolves dependencies
between premises. All following phases assume normalized templates.
The normalization allows simplifications in the implementations of the
phases.

\subsection{Templates}
A template is an intermediate representation of a typing rule that is
more suitable for the constraint generation process and defined in
Definition~\ref{def:template}.

Templates serve as the input format for the constraint generation
phase of the type checker. Besides being better suited for constraint
generation templates also have the advantage that we can adapt the
system to other specification languages by translation into
templates. The structure of the templates has no hard requirements on
the specification language, although it has to be declarative. In
general the structure of the templates is similar to the structure of
the typing rules of the specification language.

\begin{figure}
\begin{definition}{Definition of the syntax of templates}
  The Stratego implementation appends to all constructors two
  underscores to avoid name collisions with target languages. This is
  necessary as the module system of Stratego is not strong enough to
  avoid those collisions. We omit these here for the sake of
  readability. The non-terminals Inputs, Outputs, Term and Error may
  contain arbitrary terms.
  \begin{grammar}
    <Template> ::= `Template' <Premises> <Conjecture>

    <Conjecture> ::= `Conjecture' <Judg> <Name> <Pattern> <Outputs>

    <Premises> ::= $\epsilon$ | <Premise> <Dependencies> <Premises>

    <Premise> ::= `Lookup' <Ctx> <Inputs> <Outputs> <Error>
    \alt `Judgment' <Judg> <Inputs> <Binding> <Outputs> <Error>
    \alt `Eq' <Term> <Term> <Error>
    \alt `Neq' <Term> <Term> <Error>

    <Dependencies> ::= $\epsilon$ | <Judg> <Outputs> <Dependencies>

    <Name> ::= `Some' <String> | `None'

    <Judg> ::= <Int>
  \end{grammar}
\label{def:template}
\end{definition}
\end{figure}


Before we are going to describe the structure of templates in depth,
we highlight the conceptual differences between templates and typing
rules. Templates take advantage of the input/output tags of typing
judgments and context definitions by splitting everything up into an
input and output part. This will become handy in the constraint
generation phase, where we can see immediately which are the patterns
to match against the expressions and which are the output positions
that we have to compute. As described in the introduction to this
chapter, we also normalize templates. For each implicit equality in
the conclusion and premises of typing rules we add an explicit
equality. Thus every variable occurs in each judgment only
once. Further we sort premises by dependencies between their
inputs/outputs. We describe and motivate the normalization process in
the remainder of the section. The template optimization and constraint
generation phase take advantage of these normalizations and therefore
expect their inputs to be normalized.

Note: We transform all meta-variables of the specification into the
variables (\code|Var(name)|) that we use for constraint generation as
we do not need the additional information of meta-variables anymore.

\subsubsection{Premises in Templates}
Premises in templates have multiple shapes: Judgments, context
lookups, equalities and inequalities. A premise always has a (possibly
empty) list of dependencies. This list contains the number and the
outputs of the judgment the premise depends on. Later on in this
section we define what it means for a premise to have dependencies,
first we take a look at the different kinds of premises.

\begin{description}
\item[Judgments] correspond to the user defined judgments of the
  specification. They consist of the judgment number
  \refcallout{judgment:number} which refers to the position in the
  declaration section of the specification, the positions of the
  judgment marked as inputs \refcallout{judgment:inputs}, context
  modifications \refcallout{judgment:bind},
  \refcallout{judgment:reset}, \refcallout{judgment:identity}, the
  output positions of the judgments \refcallout{judgment:outputs} and
  potentially error messages \refcallout{judgment:errors}.

  The main difference between context modifications in templates and
  typing rules is that all modifications are at one place and can
  always be evaluated in the same manner. A context modification can
  either be an addition to a context \refcallout{judgment:bind} which
  consists of a context identifier (this identifier refers to the
  position in the declaration section of the specification), a list of
  inputs and a list of outputs. It can also be a context identity
  \refcallout{judgment:identity} which corresponds to a context
  meta-variable in the specification and context identities do not
  modify the context and a reset operation \refcallout{judgment:reset}
  which resets the given context and corresponds to the empty
  context. Read to context modifications from right to left to obtain
  a valid context. A detail explanation of the semantics in our type
  checker will follow in Section~\ref{sec:constr-gener}.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Judgment(
        1 %*\callout{judgment:number}*)
      , [Var("X0")] %*\callout{judgment:inputs}*)
      , [ Binding(1, [Var("X1")], [Var("X2")]) %*\callout{judgment:bind}*)
        , Reset(1) %*\callout{judgment:reset}*)
        , Ctx(2) %*\callout{judgment:identity}*)
        ]
      , [Var("X3")] %*\callout{judgment:outputs}*)
      , Some([Error([Var("X0"), "has type", "{}"])]) %*\callout{judgment:errors}*)
      )
\end{lstlisting}
\label{ex:judgment}
\end{example}

In example~\ref{ex:judgment} we have judgment one that has only one
input position \code|Var("X0")| and one output position
\code|Var("X3")|. It leaves context two as it is, resets context one
and then adds the input/output pair \code|Var("X1")| and
\code|Var("X2")| to context one. In addition it is annotate with one
error message.

\item[Context lookups] consist of the context number
  \refcallout{lookup:ctx}, of the input \refcallout{lookup:inputs} and
  of the output \refcallout{lookup:outputs} positions of the context
  lookup from the specification and potentially of error messages
  \refcallout{lookup:errors}. We do not treat look ups as normal
  judgments as their semantics is not defined within the
  specification. Therefore we have to deal with them separately in the
  type checker.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Lookup(
        1 %*\callout{lookup:ctx}*)
      , [Var("X0")] %*\callout{lookup:inputs}*)
      , [Var("X1")] %*\callout{lookup:outputs}*)
      , None() %*\callout{lookup:errors}*)
      )
\end{lstlisting}
\label{ex:lookup}
\end{example}

  In example~\ref{ex:lookup} we look up \code|Var("X0")| from
  context one and bind the result to \code|Var("X1)"|. This context
  lookup has no error messages attached.

\item[(In)equalities] are predefined judgments and therefore treated
  separately. They have a judgment number, exactly two input
  positions, no output positions and potentially an error message. The
  judgment number is used to keep track of the non-terminals of the
  (in)equality.

\begin{example}
\begin{lstlisting}[language=sltc]
Neq(4, Var("X0"), Var("X1"), None())
\end{lstlisting}
\label{ex:neq}
\end{example}

In example~\ref{ex:neq} we test if \code|Var("X0")| and
\code|Var("X1")| are not equal and provide no error message.
\end{description}

In some cases it is relevant in which order we evaluate premises. As
we have not talked about evaluation yet, we assume premises are
evaluated like functions. We provide terms for input positions an
retrieve terms for the output positions. If we take a look at
Example~\ref{ex:premise-dependencies} we see that typing rule
\code|T-Tapp| from Appendix~\ref{appendix:systemf} has two
premises. When we compare the premises with the judgment definitions,
we see that \code|%x| occurs as an input of the first
premise and as within an output position of the second premise, but
not at all in the conclusion. If we want to evaluate the first premise
we have to find a term for
\code|%x|, but that term is only provided by
the output of the second premise. Therefore we have to evaluate the
second premise first.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
judgments
TermBinding{I} "|" TypeBinding{I} "|-" Exp{I} ":" Type{O}.
Type{O} "= [" ID{I} "->" Type{I} "]" Type{I}.

rules
~U = [ %x -> ~S ] ~T
$C1 | $C2 |- ~e : all %x . ~T 
============================== T-Tapp
$C1 | $C2 |- ~e [ ~S ] : ~U
\end{lstlisting}
\label{ex:premise-dependencies}
\end{example}

We make those dependencies visible in the template language by
annotating each premise with a list of its dependencies. Those
dependencies contain the number of the premise on which the premise
depends and the output positions of that premise. The outputs are
redundant information and only added to make it easier to check which
information are proivded by that dependency.
The dependency for the first premise in
Example~\ref{ex:premise-dependencies} the would look like
\code|(1,[TAll(Var("X0"), Var("X1"))])|. In this example
\code|TAll(Var("X0"), Var("X1"))| is the only output provided by the
premise and \code|1| refers to the second premise, because we sort
premises of templates topological according to the dependencies, as we
will describe in the next section.

\subsubsection{Conclusions in Templates}
Conclusions contain the judgment identifier
\refcallout{conclusion:number}, the input positions of the judgment
\refcallout{conclusion:inputs}, the context modifications
\refcallout{conclusion:ctx} as well as the output positions of the
conclusion \refcallout{conclusion:outputs}. In contrast to the
conclusion in a typing rule from the specification, a typing rule in a
template has no error message. As it was only possible to annotate the
conclusion with error messages for implicit equalities those error
messages propagate into the premisses that are introduced to make the
implicit equalities explicit.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
Conclusion(
      3 %*\callout{conclusion:number}*)
    , ( [Var("X177")] %*\callout{conclusion:inputs}*)
      , [ Binding(2, [Var("X178")], [])
        , Ctx(2)
        ] %*\callout{conclusion:ctx}*)
      )
    , [] %*\callout{conclusion:outputs}*)
    )
\end{lstlisting}
\label{ex:conclusion}
\end{example}

Example~\ref{ex:conclusion} shows a conclusion that has judgment
number three and only one input position. The context pattern specifies
that there has to be at least one element in the second context. In
this example judgment three has no outputs.

A template consists of a name, a list of premisses with dependencies
and a conclusion. Figure~\ref{fig:template-example} shows how a
complete template looks like for the variable typing rule in the
simply typed lambda calculus. On the left side of
Figure~\ref{fig:template-example} the typing rule from the
specification is shown and on the right side its representation as a
template.

\subsection{Generation}
The Stratego rule \code|to-template| does the main part of the
template generation. It takes a rule from a specification and
transforms that rule into a template. The strategy \code|to-templates|
does that iteratively for every rule in a specification. The first
step in the conversion is the elimination of implicit equalities in
the premises and the conclusion.

For each implicit equality we create an explicit equality, by
collecting all variables that occur more than once in an input
position of a premise or conclusion. After that we create fresh names
for the collect variables and create premises that state the equality
of the fresh meta-variables. Implicit equalities in premises are not
transformed into explicit equalities if the meta-variables also occur
in the conclusion. These equalities are either ensured by explicit
equalities from the conclusion or if there are no implicit equalities
in the conclusion for this meta-variable, by the fact that this
variable occurs only once as a source and thus, cannot introduce
different values. If a meta-variable occurs more than twice we define
the equalities for the new variables transitively.

Example~\ref{ex:implicit-equalities} shows this for a typing rule of
the judgment

\begin{lstlisting}[language=sltc]
Type{O} "= [" ID{I} "->" Type{I} "]" Type{I}
\end{lstlisting}

which models type substitution in the SystemF specification in
Appendix~\ref{appendix:systemf}. On the left side of
Example~\ref{ex:implicit-equalities} you see the typing rule with an
implicit equality and on the right hand side the transformed version
without the implicit equality.

\begin{example}{~}
\newline
  \begin{minipage}[b]{.45\linewidth}
    \begin{lstlisting}[language=sltc]
=====================
~S = [ %x -> ~S ] %x
\end{lstlisting}
  \end{minipage}
  \begin{minipage}[b]{.45\linewidth}
    \begin{lstlisting}[language=sltc]
%y = %z
=====================
~S = [ %y -> ~S ] %z
\end{lstlisting}
  \end{minipage}
\label{ex:implicit-equalities}
\end{example}

If there are error messages for implicit equalities, we associate
those error messages with the corresponding implicit equalities. Then
we replace the variables in the error message by the fresh
meta-variables of the corresponding explicit equality and add the
error message as a normal error to the explicit equality.

In order to treat the introduced explicit equalities like the
equalities introduced in the type system specification, we have to
introduce corresponding judgments. This is important as we rely in the
template optimization phase on the information about the non-terminals
in the judgments.

To introduce judgments for equalities that are generated from implicit
equalities, we have to determine the non-terminals of the
equality. We infer the non-terminals by analyzing the surrounding
terms and by exploiting the scope of the meta-variable.

In case the meta-variable is directly in an input or output position
of a judgment, context binding or context lookup, we infer the
non-terminal from the judgment or context definition. Otherwise we
fetch all productions of the target language that could possibly have
produced the surrounding term and extract the non-terminal from the
corresponding position. If there is more than one production that
could have created that term, we try to disambiguate by the scope of
the meta-variable. In case there is still more than one production
with different non-terminals for this meta-variable, we raise an
exception and this equality has to be made explicit in the
specification.

After this step, there are no implicit equalities left, i.e.\ all
meta-variables within a judgment are different. As a next step we
analyze the premises of the typing rule for dependencies. One premise
depends on the other, if it uses meta-variables in input positions
that occur in an output position of another premise and not as an
input position in the conclusion. As we need to supply the input
positions with concrete terms to check if a premise holds, we can only
evaluate a dependency if we first evaluate all its dependencies. In
the generation process we do two things: We sort the premises
topologically according to their dependencies and annotate them with
the output positions of the dependencies, as described in the previous
paragraph. The implementation of this ordering is almost
standard. First we collect all premises and their dependencies in a
graph. Due to the nature of the dependency it is more natural to
create edges from a premise to the premises it depends on. As it is
easy to check if a premise has an input position that does not occur
in the conclusion but as the output of another premise. Therefore the
resulting dependency graph is a transposed dependency graph. We sort
this graph topologically with the algorithm by
Kahn~\cite{Kahn:1962:TSL:368996.369025}. The result is the reversed
order, as we used the transposed dependency graph. Therefore we
reverse the result of the topological sort. If we encounter cycles in
the dependency graph we report them and abort the template generation.

After we have resolved implicit equalities and dependencies we begin
to generate templates. This process is, except for technical
subtleties, a straight forward rewriting of the rules from the
specification.

\begin{figure}
  \centering
  \begin{minipage}{.35\linewidth}
\begin{lstlisting}[language=sltc]
%x : ~T in $C
============== T-var
$C |- %x : ~T
\end{lstlisting}
  \end{minipage}
  \begin{minipage}{.55\linewidth}
\begin{lstlisting}[language=sltc]
Template(
    Some("T-var")
  , [ ( Lookup(
          1
        , [Var("X52")]
        , [Var("X53")]
        , None()
        )
      , []
      )
    ]
  , Conclusion(
      1
    , ([Var(Var("X52"))], [Ctx(1)])
    , [Var("X53")]
    )
  )
\end{lstlisting}
  \end{minipage}
  \caption{Typing rule and template of T-Var}
  \label{fig:template-example}
\end{figure}
\section{Constraint Template Optimization}
\label{sec:constr-templ-optim}
In this section we describe and motivate the optimization strategies
we have used to reduce the number of non-syntax directed
templates. However the template optimization phase can potentially do
arbitrary modifications. We focus here on optimization strategies that
reduce ambiguities between the templates.

Informally two templates are ambiguous if it is not known a priori
which (if any) of the templates can be used to extend a derivation to
a successful derivation. Therefore we have to use the rules according
to a heuristic and to backtrack if the decision did not work out. The
goal of the optimization strategies described in this section, is to
eliminate some of those ambiguities before we even start to create
derivations.

Before introducing the optimization strategies, we define more
formally what an ambiguity is.

\begin{definition}
  A template is \textit{when-ambiguous} if there is another template
  such that there is at least one term that matches the conclusion of
  both templates.
\label{def:when-ambiguous}
\end{definition}

Definition~\ref{def:when-ambiguous} describes the general case of an
ambiguity. There is an ambiguity if there is a template that has an
syntactic overlap with another template. We call those ambiguities
when-ambiguity, because it is not clear when (i.e.\ at which point in
the derivation) we have to apply an ambiguous template.

\begin{definition}
  A template is \textit{which-ambiguous} if there is another template
  such that the set of terms matching the conclusion of both templates
  is equal.
\label{def:which-ambiguity}
\end{definition}

Definition~\ref{def:which-ambiguity} aims at more limited
ambiguities. Templates are which-ambiguous if they match exactly the
same terms. In other words their conclusions are equal modulo variable
renaming. As there are two (or more) templates that apply to exactly
the same terms, it is not the question \textit{when} we have to apply
a template, but only \textit{which} one we have to apply. The
distinction of those two kinds of ambiguities will help to implement
optimization strategies. Of course all templates that are
which-ambiguous are also when-ambiguous.

Before describing the optimization strategies we implemented, we
extend the template language to make ambiguities explicit.

\begin{definition}
    The following grammar defines the extended template language.
    \begin{grammar}
    <Template> ::= $\dots$ | `Fork' <Templates>

    <Templates> ::= <Template> <Template> | <Template> <Templates>
    \end{grammar}
\end{definition}

The new constructor \code|Fork| has a list that contains at least two
template. The idea is that templates contained in \code|Fork|s are all
when-ambiguous to each other. We later use those groups of ambiguous
templates to decide at which point in the derivation we have to decide
which template we apply. A fork with less than two templates contains
no ambiguities and is therefore always decomposed.

We do four types of optimizations in the optimization phase. First we
eliminate which-ambiguities that are due to redundancies. Second we
unfold when-ambiguous templates by inserting all possible structures
in the variables of the conclusion. Directly after this we eliminate
which-ambiguities that are due to redundancies and were created by the
unfolding. Third we remove all templates that have unsatisfiable
premises and fourth we remove all valid premisses from
templates. After those optimizations we order all templates in forks
such that the most general templates are evaluated at last.

\subsection{Which-Ambiguities}
Now we look now into the optimization of which-ambiguities. First we
identify all which-ambiguities and create \code|Fork|s of them. We
implemented this using a strategy that groups lists of templates such
that each group contains templates only which-ambiguous templates. Two
templates are which-ambiguous if they have the same judgment number
and if the term pattern and context pattern of the conclusion are
equal modulo variables. Of the resulting template groups we wrap all
groups with more than one element into a \code|Fork|.

We optimize forks containing which-ambiguities by checking whether a
template of a fork is subsumed by a template that is which-ambiguous
to that template.

\begin{definition}
  A template $t_1$ subsumes another template $t_2$ if $t_1$ and $t_2$
  are which-ambiguous to each other and
  \begin{align}
    \forall FV(p_1,q_1,\dots, p_n,q_m) \,.\, ((p_1 \land\dots\land
    p_n) \implies (q_1 \land\dots\land q_m))
  \end{align}

  where $p_1 \dots p_n$ and $q_1 \dots q_m$ are the premisses of $t_2$
  and $t_1$ respectively.
\label{def:subsumes}
\end{definition}

A template $t_2$ that is subsumed by a template $t_1$ can be removed
without changing the semantics of the type system. To show this, we
have to argue that at any position where $t_2$ can be applied, we can
also apply $t_1$. As the conclusion of both templates matches the
exact same terms, we can attempt to apply both templates at the same
positions. Now we have to ensure that whenever all premisses of $t_2$
are satisfied, all premises of $t_1$ are satisfied as well. Which is
exactly our definition of subsumption.

In Example~\ref{ex:which-ambiguity} we have two subtyping rules for
records. The rule \code|Depth-1| is the standard depth subtyping rule
for records from Appendix~\ref{appendix:stlc-records}. The other rule
\code|Depth-2| was introduced to make depth subtyping of records
reflexive.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
judgments Type{I} "<:" Type{I}.

rules

~T <: ~S
{ $R } <: { $U }
=============================== Depth-1
{ %l : ~T $R } <: { %l : ~S $U }

~T = ~S
{ $R } <: { $U }
=============================== Depth-2
{ %l : ~T $R } <: { %l : ~S $U }
\end{lstlisting}
\label{ex:which-ambiguity}
\end{example}

Now we consider the presence of a general reflexivity rule for the
subtyping relation, like:

\begin{lstlisting}
T = S
====== Refl
T <: S
\end{lstlisting}

In the presence of rule \code|Refl| the rule \code|Depth-2| is
subsumed by the rule \code|Depth-1| as the conclusions of both rules
are equal modulo variables and we can prove with the help of a
first-order formula representation of rule \code|Refl| that the
following formula holds.

\begin{multline}
  \forall r,u,t,s \,.\, ((t = s \land record(r) <: record(s)) \implies
  \\ (t <: s \land record(r) <: record(s)))
\end{multline}

The first conjunct of the conclusion can be proven by applying the
first conjunct of the premise to the first-order formula
representation of rule \code|Refl| and the second conjunction is
verbatim the second conjunct of the premise.

We try to prove that a template subsumes another for all
which-ambiguous templates using vampire by transforming the templates
into a first-order formula representation and generating the formula
of Definition~\ref{def:subsumes}. If the proof succeeds we remove the
subsumed template from the fork. If no proof can be found in the given
time limit we assume the template is not subsumed and do not delete
it. The translation of templates into a first-order formula
representation is similar to the translation of specifications into a
first-order formula representation and actually reuses most of the
code.

\subsection{When-Ambiguities}
Introducing the rule \code|Refl| rendered one of the depth subtyping
rules for records redundant and we were able to detect and remove that
redundancy. However the rule \code|Refl| introduces a when-ambiguity
into the type system, as its conclusion matches all types and not just
records and there is not just only the rule \code|Refl|.

For the examples we now assume we have the type system specification
of Appendix~\ref{appendix:stlc-records}, where types are defined as
following:

\begin{grammar}
  <Type> ::= `Int' | <Type> `->' <Type> | `{' <Record> `}'

  <Record> ::= $\epsilon$ | <ID> `:' <Type> <Record>
\end{grammar}

A template within a fork that has only variables in its conclusion
judgment is always ambiguous as a fork contains at least two
templates. We unfold such templates to make them syntax
directed. Unfolding means that we create templates with all possible
structural variants of the variables. To do this we first look up the
non-terminals of the variables in the judgment definition. For all
non-terminals we then fetch the corresponding \gls{sdf} productions
from the target language. Then we generate templates where we
instantiate the variables with all possible combinations of the
productions. Non-terminals in the productions are replaced by fresh
variables.

\begin{example}{~}

\begin{minipage}{.25\linewidth}
\begin{lstlisting}[language=sltc]
Int = Int
========== R1
Int <: Int
\end{lstlisting}
\end{minipage}
\begin{minipage}{.35\linewidth}
\begin{lstlisting}[language=sltc]
~A -> ~B = Int
=============== R2
~A -> ~B <: Int
\end{lstlisting}
\end{minipage}
\begin{minipage}{.3\linewidth}
\begin{lstlisting}[language=sltc]
Int = ~C -> ~D
=============== R3
Int <: ~C -> ~D
\end{lstlisting}
\end{minipage}

\begin{minipage}{.38\linewidth}
\begin{lstlisting}[language=sltc]
~A -> ~B = ~C -> ~D
==================== R4
~A -> ~B <: ~C -> ~D
\end{lstlisting}
\end{minipage}
\begin{minipage}{.25\linewidth}
\begin{lstlisting}[language=sltc]
{ R } = Int
============ R5
{ R } <: Int
\end{lstlisting}
\end{minipage}
\begin{minipage}{.25\linewidth}
\begin{lstlisting}[language=sltc]
Int = { S }
============ R6
Int <: { S }
\end{lstlisting}
\end{minipage}

\begin{minipage}{.30\linewidth}
\begin{lstlisting}[language=sltc]
{ R } = C -> D
=============== R7
{ R } <: C -> D
\end{lstlisting}
\end{minipage}
\begin{minipage}{.30\linewidth}
\begin{lstlisting}[language=sltc]
A -> B = { S }
=============== R8
A -> B <: { S }
\end{lstlisting}
\end{minipage}
\begin{minipage}{.30\linewidth}
\begin{lstlisting}[language=sltc]
{ R } = { S }
=============== R9
{ R } <: { S }
\end{lstlisting}
\end{minipage}
\label{ex:unfolded-refl}
\end{example}

Example~\ref{ex:unfolded-refl} shows the unfolding for the template
\code|Refl|. That unfolding creates from a not-syntax directed
templates a set of syntax directed templates. Of course the unfolding
can create new ambiguities and not all templates are applicable at
all. In the current optimization step we will try to eliminate the
newly created which ambiguities. We do this in the same way as
described before, except that we now also try to proof the formula
from Definition~\ref{def:subsumes} by structural induction. Before we
describe how we do the induction, we explain the problem at
Example~\ref{ex:unfolded-refl}.

When comparing the typing rules from Example~\ref{ex:unfolded-refl}
and the typing rules from the type system specification of the simply
typed lambda calculus from Appendix~\ref{appendix:stlc-records} we see
that the following two rules have the same conclusion module variable
renaming.

\begin{minipage}[b]{.4\linewidth}
\begin{lstlisting}[language=sltc]
~A -> ~B = ~C -> ~D
==================== R4
~A -> ~B <: ~C -> ~D
\end{lstlisting}
\end{minipage}
\begin{minipage}[b]{.5\linewidth}
\begin{lstlisting}[language=sltc]
~C <: ~A
~B <: ~D
==================== S-arrow 
~A -> ~B <: ~C -> ~D
\end{lstlisting}
\end{minipage}

We can try to show that one of these templates subsumes the other. We
now try to prove that the left template is subsumed by the right
template.
\begin{align}
  \forall a,b,c,d \,.\, (a \text{\code|->|} b = c \text{\code|->|} d \implies (c <:
  a \land b <: d)) \label{prf:direct-0} \\
  \forall a,b,c,d \,.\, (a = c \land b = d \implies (c <: a \land b <:
  d)) \label{prf:direct-1}\\
 \forall a,b,c,d \,.\, (c = a \land b = d \implies (c <: a \land b <:
 d)) \label{prf:direct-2}
\end{align}

\ref{prf:direct-1} follows from the injectivity of the type
constructor \code|->| and \ref{prf:direct-2} from the symmetry of
equality. But now we are stuck as we cannot show $c = a \implies c <:
a$ nor $b = d \implies b <: d$, because we have removed the general
reflexivity rule. However we can prove \ref{prf:direct-0} by
structural induction on $a, b, c$ and $d$. We will now prove some
cases of the induction, the other cases are analogous. We first show
the base case with $a = b = c = d = \text{\code|Int|}$.
\begin{align}
  \text{\code|Int -> Int|} = \text{\code|Int -> Int|} \implies
  (\text{\code|Int|} <: \text{\code|Int|} \land \text{\code|Int|} <:
  \text{\code|Int|}) \label{prf:induction-base}
\end{align}

The premise of the implication in the base case
\ref{prf:induction-base} is valid as the terms are syntactically
equal. The conclusion of the implication holds because of rule
\code|R1|, which was created by the unfolding.

Now we show a step case with $a = a_1 \text{\code|->|} a_2$, $b =
\text{\code|Int|}$, $c = c_1 \text{\code|->|} c_2$ and $d =
\text{\code|Int|}$.
\begin{align}
  (a_1 \text{\code|->|} a_2) \text{\code|->|} \text{\code|Int|} = (c_1
  \text{\code|->|} c_2) \text{\code|->|} \text{\code|Int|} &\implies (
  c_1 \text{\code|->|} c_2 <: a_1 \text{\code|->|} a_2\land
  \text{\code|Int|} <: \text{\code|Int|}) \\
  (a_1 \text{\code|->|} a_2) = (c_1 \text{\code|->|} c_2) \land
  \text{\code|Int|} = \text{\code|Int|} &\implies (c_1
  \text{\code|->|} c_2 <: a_1 \text{\code|->|} a_2 \land
  \text{\code|Int|} <:
  \text{\code|Int|}) \label{prf:induction-arrow-1} \\
  (a_1 \text{\code|->|} a_2) = (c_1 \text{\code|->|} c_2) &\implies
  c_1 \text{\code|->|} c_2 <: a_1 \text{\code|->|}
  a_2 \label{prf:induction-arrow-2} \\
  (c_1 \text{\code|->|} c_2) = (a_1 \text{\code|->|} a_2) &\implies
  c_1 \text{\code|->|} c_2 <: a_1 \text{\code|->|}
  a_2 \label{prf:induction-arrow-3} \\
  (a_1 <: c_1) \land (c_2 <: a_2) &\implies c_1 \text{\code|->|} c_2
  <: a_1 \text{\code|->|} a_2 \label{prf:induction-arrow-4}
\end{align}

\ref{prf:induction-arrow-1} follows from the injectivity of the type
constructor \code|->|. We can drop \code|Int| $=$ \code|Int| from the
premise of the implication as it is valid and make the second conjunct
of the conclusion true by applying rule \code|R1|, which leads to
\ref{prf:induction-arrow-2}. \ref{prf:induction-arrow-3} follows from
symmetry of equality and \ref{prf:induction-arrow-4} by applying
the induction hypothesis to $(c_1 \text{\code|->|} c_2) = (a_1
\text{\code|->|} a_2)$. \ref{prf:induction-arrow-4} holds as it is a
variant of rule \code|S-arrow|.

Not that we can apply rule \code|S-arrow| as we want to retain this
rule, but not \code|R4| as we are trying to show that this rule is
redundant. If we would need it, it would not be redundant.

We now show the case where $a = \{ r \}$, $b = \text{\code|Int|}$, $c
= \{s\}$ and $d = \text{\code|Int|}$.
\begin{align}
  \{ r \} \text{\code|->|} \text{\code|Int|} = \{ s \}
  \text{\code|->|} \text{\code|Int|} &\implies (\{s\} <: \{r\} \land
  \text{\code|Int|} <: \text{\code|Int|}) \\
  \{ r \} = \{ s \} \land \text{\code|Int|} = \text{\code|Int|}
  &\implies (\{s\} <: \{r\} \land \text{\code|Int|} <:
  \text{\code|Int|}) \label{prf:induction-record-1}\\
  \{ r \} = \{ s \} &\implies \{s\} <:
  \{r\} \label{prf:induction-record-2} \\
  \{ s \} = \{ r \} &\implies \{s\} <:
  \{r\} \label{prf:induction-record-3}
\end{align}

Here \ref{prf:induction-record-1} again follows from the injectivity
of the type constructor \code|->|. We can cancel out \code|Int| $=$
\code|Int| as it is valid and the second conjunct of the conclusion
follows from rule \code|R1|, which leads to
\ref{prf:induction-record-2}. Now \ref{prf:induction-record-3} follows
from symmetry of equality and it holds as it is a variant of rule
\code|R9|. Those were the three interesting cases of the induction the
other cases follow analogous.

Now we have shown that template \code|R4| is subsumed by template
\code|S-arrow|, thus we can remove template \code|R4|. As it would be
tedious to proof those propositions by hand, we have implemented a
tactic that attempts fully automated structural induction proofs of
this kind.

After unfolding the non-syntax directed templates we collect all
which-ambiguous templates and attempt for each pair a direct proof
that one is subsumed by the other. If this proof fails we attempt a
structural induction on all free variables.

The induction cases are generated by collecting the non-terminals for
each variable we do induction on. If there are multiple non-terminals
for a variable we collect all of them to be sure that we do not miss a
case. After we have collected the non-terminals we fetch the
corresponding productions and create every possible combination of
productions under consideration of the variable position. All
non-terminals productions are replaced by fresh and arbitrary
constants. We introduce constants instead of variables to be able to
control where induction hypothesis are applied.

\begin{example}
  Suppose we have two variables $x_1$ and $x_2$ for which we have
  collected the non-terminal \code|Type|, with the following
  productions.
  \begin{grammar}
    <Type> ::= `Int' | <Type> `->' <Type>
  \end{grammar}
  From this we create the following cases:
  \begin{multicols}{2}
  \begin{itemize}
  \item $x_1 = \text{\code|Int|}$ and $x_2 = \text{\code|Int|}$
  \item $x_1 = \text{\code|Int|}$ and $x_2 = c_1 \text{\code|->|} c_2$
  \item $x_1 = c_1 \text{\code|->|} c_2$ and $x_2 = \text{\code|Int|}$
  \item $x_2 = c_1 \text{\code|->|} c_2$ and $x_2 = c_3
    \text{\code|->|} c_4$
  \end{itemize}
  \end{multicols}
\label{ex:induction-cases}
\end{example}

What is left to do is the generation of induction hypothesis. While
creating the induction cases we keep track of the non-terminals of the
constants. In Example~\ref{ex:induction-cases} all variables have the
non-terminal \code|Type|. Now we create induction hypothesis for each
case, by substituting constants into the proposition we than to prove
such that the type of the variables in the proposition matches the
type of the substituted constants. We can do this for all constants,
as each constant is structurally smaller than the term in the
induction case. This is the case because we substituted only
non-terminals within a substructure with constants.

\subsection{Unsatisfiable Templates}
The optimization in the previous section left us with a bunch of
templates that do not seem to be applicable at all. For example look
at template \code|R2| in Example~\ref{ex:unfolded-refl}. This template
has the premise \code|~A -> ~B = Int| which is unsatisfiable, as those
terms are syntactically different. However to apply a template, we
have to satisfy all its premises. Therefore template \code|R2| is not
applicable at all.

We remove templates with an unsatisifable premise by attempting a
proof that the negation of the premise is valid. If this proof
succeeds we remove the whole template, otherwise we cannot be sure and
keep the template.

Applying this strategy to all templates of
Example~\ref{ex:unfolded-refl} after the optimization of the previous
section the following templates of the unfolding remain:
\begin{multicols}{2}
\begin{lstlisting}[language=sltc]
Int = Int
========== R1
Int <: Int
\end{lstlisting}
\begin{lstlisting}[language=sltc]
{ R } = { S }
=============== R9
{ R } <: { S }
\end{lstlisting}
\end{multicols}

\subsection{Valid Premises}
Now that we have remove templates that contain unsatisfiable premises,
we can look at premises that are always satisfied, i.e.\ at valid
premises. As they are always satisfied, we do not have to check
whether they are satisfied during type checking and can remove them
from the corresponding template.

Following the same scheme as in the previous section, we attempt a
proof that a premise is valid. If that attempt succeeds we remove the
premise from the corresponding template, otherwise we cannot be sure
and keep the premise.

If we look at the remaining rules in the previous section, we observe
that \code|Int = Int| is a valid premise. Therefore the resulting set
of unfolded templates looks like:
\begin{multicols}{2}
\begin{lstlisting}[language=sltc]

========== R1
Int <: Int
\end{lstlisting}
\begin{lstlisting}[language=sltc]
{ R } = { S }
=============== R9
{ R } <: { S }
\end{lstlisting}
\end{multicols}
If we compare the remaining rules with a set of hand-crafted syntax
directed subtyping rules for the type system in
Appendix~\ref{appendix:stlc-records}, we see that the only possible
further optimization is to show that template \code|R9| is
redundant. However this cannot be optimized with the current
strategies as we can only check if which-ambiguous templates subsume
each other and \code|R9| is strictly when-ambiguous.

\subsection{Ordering}
At the end of the optimization phase we sort the templates in the
remaining forks. Templates with a more special conclusion are in front
of forks with a more general conclusion. This ordering has the
advantage that we can evaluate the templates in a fork from left to
right, so that no general template will catch all terms. More
formally, we sort the templates within a fork by $<$, which is defined
as

\begin{align}
  t_1 < t_2 \iff \exists \varphi \,.\, t_2\cdot\varphi = t_1
\end{align}

where $\varphi$ is some substitution and $\cdot$ is substitution
application. We implement the comparison as a Stratego strategy and
use the quick sort implementation of the Stratego standard
library. The comparison strategy does the following: It checks whether
the judgment number is equal, which is always satisfied as we compare
templates within a fork. Then it checks whether the constructors of
the term and context pattern of the left operand match the
constructors of the term and context pattern of the right operand
modulo variable names.

\section{Constraint Generation}
\label{sec:constr-gener}
Constraint generation is the first phase of the generated type
checker. The inputs of this phase are templates generated from a type
system specification and the program that should be type checked. The
only input method for expression we currently support is via the
conjecture section of the specification. However it should be
straightforward to extend this phase with support for e.g.\
\code|stdin|.

The constraint generation phase is structured as follows. First we
initialize contexts and then generate constraints according to the
program's structure and the templates. After generating the
constraints we pass to the constraint solver whether the expression
should be well-typed or not.

Lets first look at the implementation of contexts. We store all
contexts in a hash table (called \emph{context store}), with the
context number as key. The contexts itself are hash tables extended
with a list that keeps track of the insertion order. Hash tables are a
convenient data structure in the Stratego standard library to store
(multiple) data points at a key. They reflect the intuition of the
context declarations as cross products of the terms corresponding to
non-terminals. It is important to track the insertion order, because
some type systems (e.g.\ ordered type systems) might rely on the
ordering within contexts. For every program expression a fresh context
store is created and initialized according to the program expression.

For the context representation we decided to use hash tables instead
of normal key-value lists to reduce the lookup time in realistic
programs which declare identifiers much less then they refer to
them. However we do not have experimental evidence if this actually
speeds up type checking, because we do not have a key-value list
implementation of contexts for reference.

Implementing contexts using extended hash tables forced us to separate
context operations from normal inputs. On the one hand this creates
more exceptional cases (e.g.\ more complex matching algorithms that
are described in Section~\ref{sec:constr-templ-optim}) and on the
other hand it leads to a modular context implementation with the
potential to exchange the implementation easily.

Before we can explain how we generate constraints, we have to define
the constraint language.

\begin{definition}{Constraint Language}
  \begin{grammar}
    <Constraint> ::= `CFail' <Error>
    \alt `CEq' <Term> <Term> <Error>
    \alt `CNeq' <Term> <Term> <Error>
  \end{grammar}
\label{def:constraint-language}
\end{definition}

We annotate all constraints with error messages. These error messages
are either generated during the constraint generation or passed
through from the specification. The constraint solver shows the error
messages if a constraint cannot be solved. In
Definition~\ref{def:constraint-language} are three types of
constraints. The constraint \code|CFail| corresponds to false and
cannot be solved. Further \code|CEq| and \code|CNeq| are equality
respectively inequality constraints.

To start the constraint generation, we need besides the templates and
the program, information about the initial contexts, the judgment
number of the typing judgment and the output positions of that
judgment. Those information are available as we read the program
expression from the conjecture section of the type system
specification. If we would only read the program expression (e.g.\
from \code|stdin|) we would need to pass information about the initial
contexts, the judgment number and the output positions separately. In
this case it makes sense to hard-code that information, as it is
unlikely to change frequently.

We have divided the main logic of constraint generation into three
Stratego strategies: \code|generate| selects the template that matches
the current term, \code|generate'| applies the current term to the
conclusion of the selected template and \code|execute| evaluates the
premises of the template. All three strategies return a tuple of the
computed outputs and the generated constraints. We wrap the computed
outputs into \code|Option| to model the absence of outputs and
constraints in cases of errors.

After initializing the contexts we call the strategy \code|generate|
with the judgment number and the inputs of the conjecture. We also
pass the expected outputs and set the parameter \code|init| to
\code|true|. This parameter is \code|false| for all other cases except
the initial call to \code|generate| and used to generate an equality
constraint for the expected and actual outputs.

Now \code|generate| calls \code|find-match| to find a template whose
conclusion matches the inputs, judgment number and the current state
of the contexts. Before \code|find-match| tests the inputs and the
current state of the contexts it filters all templates with the
correct judgment number and tests only those templates for matches. In
the case of a \code|Template| \code|find-match| checks whether the
constructors of the term pattern in the conclusion and of the input
term match. They can have variables for whole levels and match if they
have the same constructors on all levels. In addition the context
pattern of the conclusion has to reflect the current state of the
contexts. The context pattern reflects the state of the contexts if it
can be applied from left to right to the context without failures. In
case of \code|Fork| only those templates are retained int the Fork
that match.

\begin{example}
  \todo[inline]{}
\end{example}

\code|find-match| safely takes the first template that matches,
because in Section~\ref{sec:constr-templ-optim} we have ensured that
there is only one template that matches. Remember \code|Fork| is a
template as well. If no template matches, we return \code|None| for
the outputs and the singelton list containing the constraint that
always fails with an appropriate error message. If \code|find-match|
succeeds to find a template it calls \code|generate'| with that
template.

The rule \code|generate'| now evaluates the selected template
according to the given input. In order to evaluate the premisses of
the selected template we need to extract parts of the current input
term. We call the substitution of terms for variables
\emph{instantiation}. For example in a rule for function application
we have to obtain the body of the function to check its type.

We initialize variables in inputs of a judgment using a term and a
pattern which describes the structure of the term. We search a
variable in the pattern to instantiate it, by walking through the
abstract syntax tree of the pattern and record the path to the
variable. Every variable is distinct as we resolved every implicit
equality in the templates and have introduced no new implicit
equality. Therefore we can take the first and only occurrence of the
variable that matches. If we find a path to that variable, we use it
to retrieve terms from the corresponding term, by walking along the
path and fetching the node at its end. We ensure that the pattern and
term always have the same structure, otherwise we would retrieve false
positives. Because there are also other sources (e.g.\ premise
dependencies) we extend the term and pattern if needed. We call adding
to this tuple \emph{bringing into scope}.

Unless the selected rule is no fork, the evaluation works as
follows. In correspondence to the bindings in the conclusions context
pattern, we pop all terms from the contexts and bring them into
scope. This is needed for example in the typing rules for the
freshness condition in SystemF, see
Appendix~\ref{appendix:systemf}. 

If a variable is bound by the outputs of the conclusion and used as
the input of a premise but neither an output of an other premise or an
input of the conclusion, we bring the variable into scope with the
expected outputs of the conclusion. This allows to deal with typing
rules that have free variables in their premises as for instance in
the subsumption rule for subtyping.

\begin{example}{~}
\begin{lstlisting}[language=sltc]
$C |- ~e : ~S
~S <: ~T
============= T-Sub
$C |- ~e : ~T
\end{lstlisting}
\label{ex:subsumption}
\end{example}

Example~\ref{ex:subsumption} shows a subsumption rule for the type
system in Appendix~\ref{appendix:stlc-records}. In the rule \code|~T|
occurs free in the second premise. Binding it to the expected output
of \code|~T| allows to still evaluate this premise.

Now we have to replace all variables introduced by the selected
template with fresh variables, otherwise applying a template twice
would lead to collisions. All variables introduced in the previous
phases have a prefix different from \code|Y|. Therefore we replace all
variables that do not have the prefix \code|Y| with a fresh variable
with the prefix \code|Y|. Additionally this allows to verify visually
whether all variables in a constraint set are fresh.

Now we evaluate the premises of the template. A key element in the
evaluation is the instantiation of the variables in the premises as
explained above.

In Section~\ref{sec:constraint-templates} we have described that the
premises are topologically sorted. Therefore we can evaluate them in
the given order. However, to ensure that the terms of all dependencies
are available during evaluation, we have to accumulate the outputs of
the evaluated premises and add those to the patterns and terms used
for the instantiation.

The strategy \code|execute| does the evaluation of the premises. We
call \code|execute| for each premise with a copy of the contexts to
ensure that one premise cannot pollute the contexts of another
premise. We have implemented a safe version of the strategy
\code|hashtable-copy| from the standard library to ensure that after
the evaluation of the premise all copies are destroyed.

We now describe what \code|execute| does for the different types of
premises.

\begin{description}
\item[Lookup:] The inputs of the lookup are instantiated, then the
  resulting term is looked up in the corresponding context. If the
  lookup succeeds the result is returned as an output, together with a
  constraint set that contains equality constraint between the output
  pattern and the looked up output. Those constraints are annotated
  with the corresponding error message, which is instantiated and in
  which the hole (\code|{}|) is replaced by the output variables. If
  the lookup fails \code|None| is return as output together with the
  \code|CFail| constraint and an appropriate error message.
\item[(In)equality:] Equalities and inequalities are initialized and
  returned as constraints, together with the output \code|None| as
  they have no output positions.
\item[Judgment:] If the premise is a judgment it is first
  instantiated. Then we call \code|generate| on the resulting input
  term with a version of the store that has been updated according to
  the context pattern of the judgment. In addition we instantiate the
  expected outputs of the judgment to make the binding of free
  variables in premises more precise. After the call to
  \code|generate| returns we generate equality constraints for the
  bindings in the context pattern of the premise. Further we generate
  equality constraints between the output pattern and the computed
  output and instantiate the corresponding error messages. The hole
  (\code|{}|) in the error messages is here replaced by the output
  variables.
\end{description}

In the case \code|generate'| encounters a fork it evaluates all
templates contained in the fork by calling \code|generate'|. It tries
to solve the resulting constraint set and returns the outputs of the
first evaluation that succeeds. If no templates can be evaluated to a
solvable constraint set we return the constraint that always fails
with an appropriate error message. Because of the ordering of forks in
Section~\ref{sec:constr-templ-optim} this procedure ensures that rules
that potentially produce solvable constraint sets but do not make real
progress are deferred to the end.

\section{Constraint Solving}
\label{sec:constraint-solving}
Constraint solving is the last phase of the type checker. The
constraint language is simple because it only consists of three
constructs, the algorithm to solve a constraint set is simple as well.

We use unification to solve the constraint sets. To be even more
precise we use a variant of Robinson unificiation
\todo{Citation}. During the unification we compute a \gls{mgu} to
instantiate the variables in the outputs and (in case of ill-typed
programs) in the error messages that we collect every time a
constraint cannot be solved.

During unification we ensure that a certain kind of malformed
constraint set does not lead to infinite loops in the unification. If
there are only inequalities left that contain at least one variable,
we abort unification. As inequality is not transitive, we can never
solve those constraint sets.
\section{Performance}
\label{sec:performance}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report"
%%% End: 
