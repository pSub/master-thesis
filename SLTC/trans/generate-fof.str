module generate-fof

imports utils
imports fof-language
imports constraint-language
imports constraint-template-language

imports include/SLTC

signature
    constructors
        AuxCons__ : String * String * List(Prop) -> Prop

 rules
    /**
     * Top-level rule to convert specifications to first-order formulas.
     *
     * @type Module -> List(Goal)
     */
    make-conjectures : Module(ModuleDec(_),
                              imports,
                              Some(Language(_)),
                              Contexts(context-definitions),
                              MetaVariables(_),
                              Judgments(_),
                              Rules(typing-rules),
                              some-conjectures)
        -> <fof-from-specification(|context-definitions, typing-rules)> some-conjectures
    make-conjectures = failed

    /**
     * Rule to convert specifications to first-order formulas.
     *
     * @param context-definitions - the plain definitions from the specification
     * @param typing-rules - the plain typing rumes from the specification
     * @type Conjectures -> FOFGoal
     */
    fof-from-specification(|context-definitions, typing-rules) : conjectures ->
        <maybe(\Conjectures(conjectures) ->
            <map(\conjecture -> 
                FOFGoal__(<conc> (context-formulas, helper,
                                  <cleanup; make-conjecture; make-inequalities> conjecture),
                          typing-rule-formulas,
                          <cleanup; make-conjecture> conjecture)
                 \)> conjectures
               \ | [FOFGoal__(context-formulas, typing-rule-formulas)])> conjectures
        where context-formulas := <make-context-formulas> context-definitions;
              typing-rule-formulas := <map(cleanup; rewrite-typing-rule)> typing-rules
             ; helper := <collect-om(?Term__(_,_));
                         mapconcat(\Term__(name, args@[_|_]) -> [<make-univalence> (name, <length> args)|
                                                                 <make-injectivity> (name, <length> args)]\)> typing-rule-formulas
    fof-from-specification(|context-definitions, typing-rules) =
        failed(|[context-definitions, typing-rules])

    fof-from-templates(|context-definitions, typing-rules) =
        ?conjectures;
        <fof-from-specification(|context-definitions, <mapconcat(?Fork__(<id>) <+ singelton)> typing-rules)> Some(Conjectures(conjectures))
    fof-from-templates(|context-definitions, typing-rules) =
        failed(|[context-definitions, typing-rules])
    
    /**
     * Helper strategy to create context formulas.
     * @internal
     */
    make-context-formulas = map-with-index(make-contexts); flatten-list
    make-context-formulas = failed

    /**
     * Remove nodes that are not relevant for first-order formular generation.
     */
    cleanup = innermost(cleanup')
    cleanup = failed
    cleanup' : ErrorTypingJudgment(j, e) -> j
    
    /** Collects all Terms of the programming language that will result
     * in constants in the first-order representation and generates axioms
     * that say that all those that are syntacically different are indeed
     * different. Those axioms are needed, because as soon as terms get
     * nested those equalities are hard to decide.
     */
    make-inequalities : ast ->
        <{|Fresh:
           collect-all(?Term__(_) <+ \Term__(n, args) -> Term__(n, <length> args)\);
           map(try(\Term__(n, args) -> Term__(n, <newnames(|"X"); map(makeVar)> args)\));
           tails; mapconcat(make-inequality)|}> ast
    make-inequalities = failed
    
    make-inequality : [] -> []
    make-inequality : [y | ys] -> <map(\x -> Formula__("ineq", Axiom__(), <make-neq>(x, y))\)> ys
    make-inequality = failed
    
    make-injectivity = {|Fresh: where(<reset-fresh> "X"; <reset-fresh> "Y"); make-injectivity'|}
    make-injectivity' : (name, n) -> [Formula__(<conc-strings> (name, "-injective-contraposition"),
                                             Axiom__(),
                                             All__(<conc>(Xs, Ys), Impl__(<zip; map(make-neq)> (Xs, Ys),
                                                                          Neq__(Term__(name, Xs), Term__(name, Ys))))
                                             ),
                                     Formula__(<conc-strings> (name, "-injective"),
                                             Axiom__(),
                                             All__(<conc>(Xs, Ys), Impl__(Eq__(Term__(name, Xs), Term__(name, Ys)),
                                                                          <zip; map(make-eq); list-accum(make-and)> (Xs, Ys))))]
        where Xs := <newnames(|"X")> n;
              Ys := <newnames(|"Y")> n
    make-injectivity' = failed

    make-univalence : (name, n) -> Formula__(<conc-strings> (name, "-univalent"),
                                            Axiom__(),
                                            All__(["Y" | ["Z" | Xs]], Impl__([Eq__(Term__(name, Xs), Var__("Y")), Eq__(Term__(name, Xs), Var__("Z"))],
                                                  Eq__(Var__("Y"), Var__("Z"))))
                                            )
        where Xs := <newnames(|"X")> n
    make-univalence = failed

    
    /**
     * Generates context definitions.
     *
     * @type (Int, ContextDefinition) -> List(Formula)
     */
    make-contexts = {|Fresh: make-contexts'|}
    make-contexts' : (i, ContextDefinition(name, raw-non-terminals)) -> [
        Formula__(<conc-strings> ("lookup base ", name),
                  Axiom__(),
                  All__([NAME|<conc>(inputs, outputs)],
                        Pred__(lookup, <conc> (inputs, outputs, [Pred__(bind, <conc> (non-terminals,
                                                                                      <singelton> NAME))])))),
        Formula__(<conc-strings> ("lookup step ", name),
                  Axiom__(),
                  All__([NAME|<concat> [inputs, inputs2, outputs, outputs2]],
                        Impl__([Pred__(lookup, <concat> [inputs, outputs, <singelton> NAME]) | <zip; map(make-neq)> (inputs, inputs2)],
                               Pred__(lookup, <conc>(inputs, outputs, [Pred__(bind, <conc> (<map(append(|"_"))> non-terminals, <singelton> NAME))])))))
    ]
       where
           // Index non-terminals with new names
           indexed-non-terminals := <Dupl; (length; newnames(|"X"), id); zip> raw-non-terminals;
           // extract the list of new names
           non-terminals := <map(Fst; \s -> Var__(s)\)> indexed-non-terminals;
           // filter out the in- and outputs
           inputs := <filter(?(_, Hole(_, "I")); Fst; \s -> Var__(s)\)> indexed-non-terminals;
           outputs := <filter(?(_, Hole(_, "O")); Fst; \s -> Var__(s)\)> indexed-non-terminals;
           // duplicate the in- and outputs by appending underscores
           inputs2 := <map(append(|"_"))> inputs;
           outputs2 := <map(append(|"_"))> outputs;
           
           // Auxiliary definitions
           lookup := <conc-strings> ("lookup", <int-to-string> i);
           bind := <conc-strings> ("bind", <int-to-string> i);
           NAME := Var__(<make-fresh> "X")
           append(|p) = \ Var__(s) -> Var__(<conc-strings> (s, p)) \
    make-contexts' = failed

           
    /**
     * Translates all generic construtors into an auxillary data structure.
     */
    make-aux-cons : cons#(args) -> AuxCons__(constant, generic, args)
        where
            [constant, generic] := <string-tokenize(|<singelton> '-')> cons;
            <is-generic> constant
            is-generic = "ContextEmpty" <+
                         "ContextBind" <+
                         "ContextLookup" <+
                         "TypingJudgment" <+
                         "MetaVariable" <+
                         "Eq" <+
                         "Neq" <+
                         "Not" <+
                         "Const"
    
    /**
     * Wraps meta-variables into an auxiliary constructor.
     */
    rewrite-meta-variable : AuxCons__("MetaVariable", scope, [name, _]) -> Var__(name, scope)
    
    /**
     * Wraps contexts in an auxiliary constructor.
     */
    rewrite-context-empty : AuxCons__("ContextEmpty", name, []) -> Pred__(<concat-strings> ["empty", name])
    rewrite-context-bind : AuxCons__("ContextBind", name, args) -> Pred__(<concat-strings> ["bind", name], args)
    rewrite-context-lookup : AuxCons__("ContextLookup", name, args) -> Pred__(<concat-strings> ["lookup", name], args)
    rewrite-context = rewrite-context-empty <+ rewrite-context-bind <+ rewrite-context-lookup

    /**
     * Wraps typing judgment in an auxiliary constructor.
     */
    rewrite-typing-judgment : AuxCons__("TypingJudgment", "False", []) -> Eq__(1, 0)
    rewrite-typing-judgment : AuxCons__("Neq", _, [arg1, arg2]) -> Neq__(arg1, arg2)
    rewrite-typing-judgment : AuxCons__("Eq", _, [arg1, arg2]) -> Eq__(arg1, arg2)
    rewrite-typing-judgment : AuxCons__("Not", _, [arg]) -> Not__(arg)
    rewrite-typing-judgment : AuxCons__("TypingJudgment", name, args) -> Pred__(<conc-strings>("'tcheck", name, "'"), args)

    /**
     * `make-formula' for axioms.
     */
    rewrite-typing-rule = make-formula(|Axiom__())
    rewrite-typing-rule = failed

    /**
     * `make-formula' for conjectures.
     */
    make-conjecture = make-formula(|Conjecture__())
    make-conjecture = failed

    /**
     * Transforms typing rules, templates and formuals with raw terms into first-order formulas.
     */
    make-formula(|type) : TypingRule(premises, RuleName(_, name), consequence)
                           -> Formula__(<option-to-string-newname(|<type-to-string> type)> name, type, prop)
       where // Rewrite consequence and premises and collect all free variables
            consequence' := <rewrite> consequence;
            premisses' := <to-list(PremiseBase, PremiseCons); rewrite> premises;
            free-vars-in-rule := <union> (<free-vars> premisses', <free-vars> consequence');
            implication := <if <[]> premisses' then !consequence' else !Impl__(premisses', consequence') end>;
            // if there are non free variables omit quantification as
            // it is illegal in TPTP to quantify over no variables.
            prop := <if <[]> free-vars-in-rule then !implication else !All__(free-vars-in-rule, implication) end>

    make-formula(|type) : Template__(name, calls, Conclusion__(judg-number, (pattern, ctx), outputs))
                            -> Formula__(<option-to-string-newname(|<type-to-string> type)> name, type, prop)
        where
            conclusion := Pred__(<conc-strings>("'tcheck", <int-to-string> judg-number , "'")
                                , <concat> [<rewrite-pattern> pattern, <rewrite-ctx> ctx, <rewrite-pattern> outputs]);
            premisses := <map(rewrite-call)> calls;
            formula := <if <[]> calls then !conclusion else !Impl__(premisses, conclusion) end>;
            free-vars-in-rule := <free-vars> formula;
            prop := <if <[]> free-vars-in-rule then !formula else !All__(free-vars-in-rule, formula) end>

    make-formula(|type) : Formula__(name, prop) -> Formula__(name, type, prop'')
        where
            prop' := <rewrite-pattern> prop;
            free-vars-in-rule := <free-vars> prop';
            prop'' := <if <[]> free-vars-in-rule then !prop' else !All__(free-vars-in-rule, prop') end>

    make-formula(|type) = failed(|[type])

    /**
     * Helper rule to transform premisses of templates into first-order predicates.
     */
    premisses-to-props : Template__(_, calls, _) -> <map(rewrite-call)> calls
    premisses-to-props = failed

    /**
     * Transforms a term that is not a context into a first-order term.
     */
    rewrite-pattern = topdown(try(make-term)); topdown(try(rewrite-string))
    rewrite-pattern = failed

    /**
     * Rewrite whole context modification descriptions of templates into first-order terms
     */
    rewrite-ctx = group(\(c1, c2) -> <equal> (<get-ctx-id> c1, <get-ctx-id> c2)\);
                  map(reverse; \l -> <foldl(\(Binding__(ctx, i, o), b) -> Pred__(<concat-strings> ["bind", <int-to-string> ctx], <conc> (i, o, [b])) \)> (<Tl> l, <Hd; convert-ctx> l)\)
    rewrite-ctx = failed


    /**
     * Converts Reset and Ctx into equivalent first-order term.
     * @internal
     */
    convert-ctx : Reset__(ctx) -> Pred__(<concat-strings> ["empty", <int-to-string> ctx])
    convert-ctx : Ctx__(ctx) -> Var__(<concat-strings> ["C", <int-to-string> ctx])
    convert-ctx = failed
    
    /**
     * Rewrites a premisse of a template into a proposition.
     * @internal
     */
    rewrite-call : (Lookup__(ctx, inputs, outputs, error), _) ->
        Pred__(<concat-strings> ["lookup", <int-to-string> ctx],
               <conc> (<rewrite-pattern> inputs, <rewrite-pattern> outputs))
    rewrite-call : (Judgment__(n, t, binding, outputs, error), _) ->
        Pred__(<conc-strings>("'tcheck", <int-to-string> n, "'"),
               <conc> (<rewrite-pattern> t,
                       <rewrite-ctx> binding,
                       <rewrite-pattern> outputs))
    rewrite-call : (Eq__(num, a, b, _), _) -> Eq__(<rewrite-pattern> a, <rewrite-pattern> b)
    rewrite-call : (Neq__(num, a, b, _), _) -> Neq__(<rewrite-pattern> a, <rewrite-pattern> b)
    rewrite-call = failed

    /**
     * Wrap strings into terms.
     *
     * @type String -> Term__(n)
     */
    wrap-string : v -> Term__(v)
       where <is-string; string-as-chars(map(is-alphanum))> v

    /**
     * Wrap all strings that are arguments of Term__ or Pred__ into terms.
     */
    rewrite-string : Term__(n, args) -> Term__(n, <map(try(wrap-string))> args)
    rewrite-string : Pred__(n, args) -> Pred__(n, <map(try(wrap-string))> args)
    
    /**
     * Wraps the constructors of the programming language into terms, i.e. wraps
     * all nodes with an unknown constructor.
     */
    make-term : v -> v
       where <is-string> v
    make-term : cons#([]) -> Term__(<lower-case> cons)
       where <not([])> cons;
       prop-constructors := ["True", "False"];
             <not(fetch-elem(\prop-cons ->  <equal(|<conc-strings> (prop-cons, "__"), cons)> \))> prop-constructors
    make-term : cons#(args) -> Term__(<lower-case> cons, args)
       where <not([])> cons;
             prop-constructors := ["All", "Not", "And", "Or", "Impl", "BiImpl", "Formula",
                                   "Eq", "Neq", "Var", "Pred", "Term", "All", "Exists",
                                   "True", "False", "Const"];
             <not(fetch-elem(\prop-cons ->  <equal(|<conc-strings> (prop-cons, "__"), cons)> \))> prop-constructors


strategies
    /**
     * Main strategy that apply all transformations to create valid TPTP formulas.
     */
    toFOF = make-conjectures; {|Fresh: make-variables-unique|}; remove-dashes

    /**
     * Try to apply all rules that rewrite auxilary constructors.
     */
    rewrite-aux-cons = rewrite-context <+ rewrite-typing-judgment <+ rewrite-meta-variable
    
    /**
     * Rewrite the AST topdown. If an auxilary construtor can be created rewrite it immediatly,
     * otherwise try to create a term. After the first topdown traversal, traverse the AST again
     * topdown to rewrite all relevant strings into terms.
     */
    rewrite = topdown(make-aux-cons < rewrite-aux-cons + try(make-term)); topdown(try(rewrite-string))
    
    /**
     * Ensure that all variables are uniquely named and are valid TPTP names. Before that run all Variables are scoped, thus
     * all scoped variables are collected. After this the AST is folded over the collected variables. In the AST the scoped
     * variable nodes are replaced with unscoped fresh variables, variable by variable.
     */
    make-variables-unique =
        ?ast;
        collect-all(?Var__(_,_)); Dupl;
        (id, length; newnames(|"X"); map(\x -> Var__(x)\));
        zip; replace-all(|ast)
    make-variables-unique = failed
                                  
    /**
     * Dashes in predicate names are not valid in TPTP.
     *
     * FIXME: It would be nice, if it is guaranteed, that the renaming creates no collisions
     * FIXME: Try to rename other invalid characters
     */
    remove-dashes = topdown(try(\Term__(name, args) -> Term__(<string-replace(|"-", "")> name, args)\ <+
                               \Term__(name) -> Term__(<string-replace(|"-", "")> name)\))
    remove-dashes = failed