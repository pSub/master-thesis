module generate-fof

imports utils
imports include/SLTC

signature
	//FIXME: What is the advantage of defining the sorts explicitly
	sorts Prop Type FOF File
	constructors
	    // Constructors are postfixed with two underscores to
	    // avoid collisions with other constructors.
		False__ : Prop
    	True__  : Prop
    	Not__   : Prop -> Prop
    	And__   : Prop * Prop -> Prop
    	Or__    : Prop * Prop -> Prop
    	Impl__  : List(Prop) * Prop -> Prop
    	BiImpl__ : Prop * Prop -> Prop
    	Eq__    : Prop * Prop -> Prop
    	Neq__ : Prop * Prop -> Prop
    	Var__   : String -> Prop                   // variables
    	Var__   : String * String -> Prop          // variables annotated with a scope
    	Pred__  : String -> Prop                   // Constants
    	Pred__  : String * List(Prop) -> Prop      // Predicates consisting of a name and a list of arguments
    	Term__  : String -> Prop                   // Terms
    	Term__  : String * List(Prop) -> Prop      // Terms
    	All__   : List(Var) * Prop -> Prop
    	Exists__ : List(Var) * Prop -> Prop
    	
    	Axiom__ : Type
    	Conjecture__ : Type
    	
    	Formula__ : String * Type * Prop -> FOF
    	Formula__ : String * Prop -> FOF
    	FOFGoal__ : List(Formula) * List(Formula) -> File
    	FOFGoal__ : List(Formula) * List(Formula) * Formula -> File
		
		AuxCons__ : String * String * List(Prop) -> Prop

 rules
	makeConjectures : Module(ModuleDec(_),
			                 imports,
			                 Language(_),
			                 MetaVariables(_),
			                 Contexts(ContextDefinitions),
			                 Judgments(_),
			                 Rules(TypingRules),
			                 some-conjectures)
			          -> <maybe(\Conjectures(conjectures) ->
			                      <map(\conjecture -> 
			                             FOFGoal__(<conc> (aux-formulas,
			                                               <makeConjecture; makeInequalities> conjecture),
			                                        typing-rule-formulas,
			                                        <cleanup; makeConjecture> conjecture)
			                           \)> conjectures
			                   \ | [FOFGoal__(aux-formulas, typing-rule-formulas)])> some-conjectures
        where
            context-formulas := <map-with-index(makeContexts); flatten-list> ContextDefinitions;
            typing-rule-formulas := <map(cleanup; rewriteTypingRule)> TypingRules;
            
            // Create the injectivity and univalence formulas
            helper := <collect-all(?Term__(_, _)); nub;
            		   mapconcat(\Term__(name, args) -> [ <makeInjectivity> (name, <length> args)
            		   			                        , <makeUnivalence> (name, <length> args)
            		   			                        ]
            		   			 \)> typing-rule-formulas;
            aux-formulas := context-formulas //<conc> (context-formulas, helper)

    /**
     * Remove nodes that are not relevant for first-order formular generation.
     */
    cleanup = innermost(cleanup')
    cleanup' : ErrorTypingJudgment(j, e) -> j

    // Auxilary function that allows 'pointfree' notation. 
    makeNeq : (x,y) -> Neq__(x,y)
    
    // Collects all Terms of the programming language that will result in constants in the first-order representation
    // and generates axioms that say that all those that are syntacically different are indeed different.
    // Those axioms are needed, because as soon as terms get nested those equalities are hard to decide.
	makeInequalities : ast -> <collect-all(?Term__(_)); nub; tails; mapconcat(makeInequality)> ast
	makeInequality : [] -> []
	makeInequality : [y | ys] -> <map(\x -> Formula__("ineq", Axiom__(), <makeNeq>(x, y))\)> ys
    
    //TODO: Is the formulation important? What about using the contraposition?
    //FIXME: It seems those are not used at all. Check why that is and remove if they are superfluous.
    makeInjectivity : (name, n) -> Formula__(<conc-strings> (name, "-injective"),
    									     Axiom__(),
									         All__(<conc>(Xs, Ys), Impl__(<zip; map(makeNeq)> (Xs, Ys),
									                                      Neq__(Term__(name, Xs), Term__(name, Ys))))
    									     )
    	where Xs := <newnames(|"X")> n;
    		  Ys := <newnames(|"Y")> n
    makeUnivalence : (name, n) -> Formula__(<conc-strings> (name, "-univalent"),
    									    Axiom__(),
									        All__(["Y" | ["Z" | Xs]], Impl__([Eq__(Term__(name, Xs), Var__("Y")), Eq__(Term__(name, Xs), Var__("Z"))],
									              Eq__(Var__("Y"), Var__("Z"))))
    									    )
    	where Xs := <newnames(|"X")> n
    

    // Collect free variables
    free-vars : v@Var__(_) -> <strip-annos; singelton> v
    free-vars : v@Var__(_,_) -> <strip-annos; singelton> v
    free-vars : All__(vars, prop) -> <diff> (<free-vars> prop, <free-vars> vars)
    free-vars : Exists__(vars, prop) -> <diff> (<free-vars> prop, <free-vars> vars)
    free-vars : cons#(xs) -> <map(free-vars); unions> xs
	
	// Generate context definitions
	makeContexts : (i, ContextDefinition(name, raw-non-terminals)) -> [
	    Formula__(<conc-strings> ("lookup base ", name),
	              Axiom__(),
	              All__([NAME|<conc>(inputs, outputs)],
	                    Pred__(lookup, <conc> (inputs, outputs, [Pred__(bind, <conc> (non-terminals,
	                                                                                  <singelton> NAME))])))),
	    Formula__(<conc-strings> ("lookup step ", name),
	              Axiom__(),
	              All__([NAME|<concat> [inputs, inputs2, outputs, outputs2]],
	                    Impl__([Pred__(lookup, <concat> [inputs, outputs, <singelton> NAME]) | <zip; map(makeNeq)> (inputs, inputs2)],
	                           Pred__(lookup, <conc>(inputs, outputs, [Pred__(bind, <conc> (<map(append(|"_"))> non-terminals, <singelton> NAME))])))))
	]
	   where
	       // Index non-terminals with new names
	       indexed-non-terminals := <Dupl; (length; newnames(|"X"), id); zip> raw-non-terminals;
		   // extract the list of new names
	       non-terminals := <map(Fst; \s -> Var__(s)\)> indexed-non-terminals;
	       // filter out the in- and outputs
	       inputs := <filter(?(_, Hole(_, "I")); Fst; \s -> Var__(s)\)> indexed-non-terminals;
	       outputs := <filter(?(_, Hole(_, "O")); Fst; \s -> Var__(s)\)> indexed-non-terminals;
	       // duplicate the in- and outputs by appending underscores
	       inputs2 := <map(append(|"_"))> inputs;
	       outputs2 := <map(append(|"_"))> outputs;
	       
	       // Auxiliary definitions
	       lookup := <conc-strings> ("lookup", <int-to-string> i);
	       bind := <conc-strings> ("bind", <int-to-string> i);
	       NAME := Var__(<newname> "X")
           append(|p) = \ Var__(s) -> Var__(<conc-strings> (s, p)) \

	       
    // Translate all generic construtors into an auxillary data structure
    makeAuxCons : cons#(args) -> AuxCons__(constant, generic, args)
        where
            [constant, generic] := <string-tokenize(|<singelton> '-')> cons;
            <is-generic> constant
            is-generic = "ContextEmpty" <+
            			 "ContextBind" <+
            			 "ContextLookup" <+
            			 "TypingJudgment" <+
            			 "MetaVariable"
    
    // Meta-variables
    rewriteMetaVariable : AuxCons__("MetaVariable", scope, name) -> Var__(<concat-strings> name, scope)
	
	// Contexts in typing rules
	rewriteContextEmpty : AuxCons__("ContextEmpty", name, []) -> Pred__(<concat-strings> ["empty", name])
	rewriteContextBind : AuxCons__("ContextBind", name, args) -> Pred__(<concat-strings> ["bind", name], args)
	rewriteContextLookup : AuxCons__("ContextLookup", name, args) -> Pred__(<concat-strings> ["lookup", name], args)
	rewriteContext = rewriteContextEmpty <+ rewriteContextBind <+ rewriteContextLookup

	// Typing judgments
	rewriteTypingJudgment : AuxCons__("TypingJudgment", "Neq", [arg1, arg2]) -> Neq__(arg1, arg2)
	rewriteTypingJudgment : AuxCons__("TypingJudgment", "Eq", [arg1, arg2]) -> Eq__(arg1, arg2)
	rewriteTypingJudgment : AuxCons__("TypingJudgment", "Not", [arg]) -> Not__(arg)
	rewriteTypingJudgment : AuxCons__("TypingJudgment", name, args) -> Pred__(<conc-strings>("'tcheck", name, "'"), args)
			
	// Typing rules
	rewriteTypingRule : TypingRule(RuleName(_, Name), consequence) -> Formula__(<option-to-string-newname(|"formula")> Name, Axiom__(), prop)
	   with // Rewrite consequence and collect all free variables
	   	    consequence' := <rewrite> consequence;
	        free-vars-in-rule := <free-vars> consequence';
	        // if there are non free variables omit quantification as
	        // it is illegal in TPTP to quantify over no variables.
	        prop := <if [] then <id> consequence' else <id> All__(free-vars-in-rule, consequence') end> free-vars-in-rule
	        
	rewriteTypingRule : TypingRule(premises, RuleName(_, Name), consequence) 
	                       -> Formula__(<option-to-string-newname(|"formula")> Name, Axiom__(), prop)
	   with // Rewrite consequence and premises and collect all free variables
	   	    consequence' := <rewrite> consequence;
            premises' := <to-list(PremiseBase, PremiseCons); rewrite> premises;
	        free-vars-in-rule := <union> (<free-vars> premises', <free-vars> consequence');
	        implication := Impl__(premises', consequence');
			// if there are non free variables omit quantification as
	        // it is illegal in TPTP to quantify over no variables.
	        prop := <if [] then <id> implication else <id> All__(free-vars-in-rule, implication) end> free-vars-in-rule
	        
	// Conjectures
	// FIXME: Doesn't it make sense to quantify over variables in conjectures
	makeConjecture : TypingRule(RuleName(_, Name), consequence) 
	                   -> Formula__(<option-to-string-newname(|"goal")> Name, Conjecture__(), consequence')
       with consequence' := <rewrite> consequence
    makeConjecture : TypingRule(premises, RuleName(_, Name), consequence) 
                       -> Formula__(<option-to-string-newname(|"goal")> Name, Conjecture__(), implication)
       with consequence' := <rewrite> consequence;
            premises' := <to-list(PremiseBase, PremiseCons); rewrite> premises;
            implication := Impl__(premises', consequence')

    // Wrap strings into terms
	wrapString : v -> Term__(v)
	   where <is-string ; string-as-chars(map(is-alphanum))> v

	// Wrap all strings that are parameters of Term__ or Pred__ into terms
	rewriteString : Term__(n, args) -> Term__(n, <map(try(wrapString))> args)
	rewriteString : Pred__(n, args) -> Pred__(n, <map(try(wrapString))> args)
	
	// Wrap the constructors of the programming language into terms
	makeTerm : v -> v
	   where <is-string> v
	makeTerm : cons#([]) -> Term__(<lower-case> cons)
	   where <not([])> cons
    makeTerm : cons#(args) -> Term__(<lower-case> cons, args)
       where <not([])> cons;
             not(<conc-strings; (prop-constructor, "__")> cons)
       prop-constructor = "All" <+ "Not" <+ "And" <+ "Or"   <+ "Impl" <+ "BiImpl" <+ "Formula" <+
                          "Eq"  <+ "Neq" <+ "Var" <+ "Pred" <+ "Term" <+ "All"    <+ "Exists"

strategies
    // Main strategy that apply all transformations to create valid TPT formulas
	toFOF = makeConjectures; makeVariablesUnique; removeDashes

    // Try to apply all rules that rewrite auxilary constructors
	rewriteAuxCons = rewriteContext <+ rewriteTypingJudgment <+ rewriteMetaVariable
	
	// Rewrite the AST topdown. If an auxilary construtor can be created rewrite it immediatly,
	// otherwise try to create a term. After the first topdown traversal, traverse the AST again
	// topdown to rewrite all relevant strings into terms.
	rewrite = topdown(makeAuxCons < rewriteAuxCons + try(makeTerm)); topdown(try(rewriteString))
	
	// Ensure that all variables are uniquely named and are valid TPTP names. Before that run all Variables are scoped, thus
	// all scoped variables are collected. After this the AST is folded over the collected variables. In the AST the scoped
	// variable nodes are replaced with unscoped fresh variables, variable by variable.
	makeVariablesUnique = (Dupl; (collect-all(?Var__(_,_)), id)) < foldl(\(v, f) -> <replace(|v, Var__(<newname> "X"), f)> \)
	                                                               + fail
	                                                               
	// Dashes in predicate names are not valid in TPTP
	// FIXME: It would be nice, if it is guaranteed, that the renaming creates no collisions
	// FIXME: Try to rename other invalid characters
	removeDashes = topdown(try(\Term__(name, args) -> Term__(<string-replace(|"-", "")> name, args)\ <+
	                           \Term__(name) -> Term__(<string-replace(|"-", "")> name)\))