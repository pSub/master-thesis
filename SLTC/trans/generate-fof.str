module generate-fof

imports utils
imports constraint-language
imports constraint-template-language

imports include/SLTC

signature
	//FIXME: What is the advantage of defining the sorts explicitly
	sorts Prop Type FOF File
	constructors
	    // Constructors are postfixed with two underscores to
	    // avoid collisions with other constructors.
		False__ : Prop
    	True__  : Prop
    	Not__   : Prop -> Prop
    	And__   : Prop * Prop -> Prop
    	Or__    : Prop * Prop -> Prop
    	Impl__  : List(Prop) * Prop -> Prop
    	BiImpl__ : Prop * Prop -> Prop
    	Eq__    : Prop * Prop -> Prop
    	Neq__ : Prop * Prop -> Prop
    	Var__   : String -> Prop                   // variables
    	Var__   : String * String -> Prop          // variables annotated with a scope
    	Pred__  : String -> Prop                   // Constants
    	Pred__  : String * List(Prop) -> Prop      // Predicates consisting of a name and a list of arguments
    	Term__  : String -> Prop                   // Terms
    	Term__  : String * List(Prop) -> Prop      // Terms
    	All__   : List(Var) * Prop -> Prop
    	Exists__ : List(Var) * Prop -> Prop
    	
    	Axiom__ : Type
    	Conjecture__ : Type
    	
    	Formula__ : String * Type * Prop -> FOF
    	Formula__ : String * Prop -> FOF
    	FOFGoal__ : List(Formula) * List(Formula) -> File
    	FOFGoal__ : List(Formula) * List(Formula) * Formula -> File
		
		AuxCons__ : String * String * List(Prop) -> Prop

 rules
	makeConjectures : Module(ModuleDec(_),
			                 imports,
			                 Language(_),
			                 MetaVariables(_),
			                 Contexts(context-definitions),
			                 Judgments(_),
			                 Rules(typing-rules),
			                 some-conjectures)
			          -> <fof-from-specification(|context-definitions, typing-rules)> some-conjectures
            
    fof-from-specification(|context-definitions, typing-rules) : conjectures ->
        <maybe(\Conjectures(conjectures) ->
            <map(\conjecture -> 
                FOFGoal__(<conc> (context-formulas,
                                  <cleanup; makeConjecture; makeInequalities> conjecture),
                          typing-rule-formulas,
                          <cleanup; makeConjecture> conjecture)
                 \)> conjectures
               \ | [FOFGoal__(context-formulas, typing-rule-formulas)])> conjectures
        where context-formulas := <make-context-formulas> context-definitions;
              typing-rule-formulas := <map(cleanup; rewriteTypingRule)> typing-rules

    fof-from-templates(|context-definitions, typing-rules) : conjectures ->
        <map(\conjecture ->
                FOFGoal__(<conc> (<make-context-formulas> context-definitions,
                          <makeConjecture; makeInequalities> conjecture),
                  <map(rewriteTypingRule)> typing-rules,
                  <makeConjecture> conjecture)
             \)> conjectures
    
    make-context-formulas = map-with-index(makeContexts); flatten-list

    /**
     * Remove nodes that are not relevant for first-order formular generation.
     */
    cleanup = innermost(cleanup')
    cleanup' : ErrorTypingJudgment(j, e) -> j

    // Auxilary function that allows 'pointfree' notation. 
    makeNeq : (x,y) -> Neq__(x,y)
    
    // Collects all Terms of the programming language that will result in constants in the first-order representation
    // and generates axioms that say that all those that are syntacically different are indeed different.
    // Those axioms are needed, because as soon as terms get nested those equalities are hard to decide.
	makeInequalities : ast -> <collect-all(?Term__(_)); nub; tails; mapconcat(makeInequality)> ast
	makeInequality : [] -> []
	makeInequality : [y | ys] -> <map(\x -> Formula__("ineq", Axiom__(), <makeNeq>(x, y))\)> ys
    
    //TODO: Is the formulation important? What about using the contraposition?
    //FIXME: It seems those are not used at all. Check why that is and remove if they are superfluous.
    makeInjectivity : (name, n) -> Formula__(<conc-strings> (name, "-injective"),
    									     Axiom__(),
									         All__(<conc>(Xs, Ys), Impl__(<zip; map(makeNeq)> (Xs, Ys),
									                                      Neq__(Term__(name, Xs), Term__(name, Ys))))
    									     )
    	where Xs := <newnames(|"X")> n;
    		  Ys := <newnames(|"Y")> n
    makeUnivalence : (name, n) -> Formula__(<conc-strings> (name, "-univalent"),
    									    Axiom__(),
									        All__(["Y" | ["Z" | Xs]], Impl__([Eq__(Term__(name, Xs), Var__("Y")), Eq__(Term__(name, Xs), Var__("Z"))],
									              Eq__(Var__("Y"), Var__("Z"))))
    									    )
    	where Xs := <newnames(|"X")> n
    

    // Collect free variables
    free-vars : v@Var__(_) -> <strip-annos; singelton> v
    free-vars : v@Var__(_,_) -> <strip-annos; singelton> v
    free-vars : All__(vars, prop) -> <diff> (<free-vars> prop, <free-vars> vars)
    free-vars : Exists__(vars, prop) -> <diff> (<free-vars> prop, <free-vars> vars)
    free-vars : cons#(xs) -> <map(free-vars); unions> xs
	
	// Generate context definitions
	makeContexts : (i, ContextDefinition(name, raw-non-terminals)) -> [
	    Formula__(<conc-strings> ("lookup base ", name),
	              Axiom__(),
	              All__([NAME|<conc>(inputs, outputs)],
	                    Pred__(lookup, <conc> (inputs, outputs, [Pred__(bind, <conc> (non-terminals,
	                                                                                  <singelton> NAME))])))),
	    Formula__(<conc-strings> ("lookup step ", name),
	              Axiom__(),
	              All__([NAME|<concat> [inputs, inputs2, outputs, outputs2]],
	                    Impl__([Pred__(lookup, <concat> [inputs, outputs, <singelton> NAME]) | <zip; map(makeNeq)> (inputs, inputs2)],
	                           Pred__(lookup, <conc>(inputs, outputs, [Pred__(bind, <conc> (<map(append(|"_"))> non-terminals, <singelton> NAME))])))))
	]
	   where
	       // Index non-terminals with new names
	       indexed-non-terminals := <Dupl; (length; newnames(|"X"), id); zip> raw-non-terminals;
		   // extract the list of new names
	       non-terminals := <map(Fst; \s -> Var__(s)\)> indexed-non-terminals;
	       // filter out the in- and outputs
	       inputs := <filter(?(_, Hole(_, "I")); Fst; \s -> Var__(s)\)> indexed-non-terminals;
	       outputs := <filter(?(_, Hole(_, "O")); Fst; \s -> Var__(s)\)> indexed-non-terminals;
	       // duplicate the in- and outputs by appending underscores
	       inputs2 := <map(append(|"_"))> inputs;
	       outputs2 := <map(append(|"_"))> outputs;
	       
	       // Auxiliary definitions
	       lookup := <conc-strings> ("lookup", <int-to-string> i);
	       bind := <conc-strings> ("bind", <int-to-string> i);
	       NAME := Var__(<newname> "X")
           append(|p) = \ Var__(s) -> Var__(<conc-strings> (s, p)) \

	       
    // Translate all generic construtors into an auxillary data structure
    makeAuxCons : cons#(args) -> AuxCons__(constant, generic, args)
        where
            [constant, generic] := <string-tokenize(|<singelton> '-')> cons;
            <is-generic> constant
            is-generic = "ContextEmpty" <+
            			 "ContextBind" <+
            			 "ContextLookup" <+
            			 "TypingJudgment" <+
            			 "MetaVariable"
    
    // Meta-variables
    rewriteMetaVariable : AuxCons__("MetaVariable", scope, [name, _]) -> Var__(name, scope)
	
	// Contexts in typing rules
	rewriteContextEmpty : AuxCons__("ContextEmpty", name, []) -> Pred__(<concat-strings> ["empty", name])
	rewriteContextBind : AuxCons__("ContextBind", name, args) -> Pred__(<concat-strings> ["bind", name], args)
	rewriteContextLookup : AuxCons__("ContextLookup", name, args) -> Pred__(<concat-strings> ["lookup", name], args)
	rewriteContext = rewriteContextEmpty <+ rewriteContextBind <+ rewriteContextLookup

	// Typing judgments
	rewriteTypingJudgment : AuxCons__("TypingJudgment", "False", []) -> False__()
	rewriteTypingJudgment : AuxCons__("TypingJudgment", "Neq", [arg1, arg2]) -> Neq__(arg1, arg2)
	rewriteTypingJudgment : AuxCons__("TypingJudgment", "Eq", [arg1, arg2]) -> Eq__(arg1, arg2)
	rewriteTypingJudgment : AuxCons__("TypingJudgment", "Not", [arg]) -> Not__(arg)
	rewriteTypingJudgment : AuxCons__("TypingJudgment", name, args) -> Pred__(<conc-strings>("'tcheck", name, "'"), args)

	rewriteTypingRule = makeFormula(|Axiom__())
	makeConjecture = makeFormula(|Conjecture__())

    type-to-string : Axiom__() -> "formula"
    type-to-string : Conjecture__() -> "goal"

    makeFormula(|type) : TypingRule(PremiseBase(), RuleName(_, name), consequence)
                     -> Formula__(<option-to-string-newname(|<type-to-string> type)> name, type, prop)
       where // Rewrite consequence and collect all free variables
            consequence' := <rewrite> consequence;
            free-vars-in-rule := <free-vars> consequence';
            // if there are non free variables omit quantification as
            // it is illegal in TPTP to quantify over no variables.
            prop := <if [] then <id> consequence' else <id> All__(free-vars-in-rule, consequence') end> free-vars-in-rule

    makeFormula(|type) : TypingRule(premises, RuleName(_, name), consequence)
                           -> Formula__(<option-to-string-newname(|<type-to-string> type)> name, type, prop)
       where // Rewrite consequence and premises and collect all free variables
            consequence' := <rewrite> consequence;
            premises' := <to-list(PremiseBase, PremiseCons); rewrite> premises;
            free-vars-in-rule := <union> (<free-vars> premises', <free-vars> consequence');
            implication := Impl__(premises', consequence');
            // if there are non free variables omit quantification as
            // it is illegal in TPTP to quantify over no variables.
            prop := <if [] then <id> implication else <id> All__(free-vars-in-rule, implication) end> free-vars-in-rule

    makeFormula(|type) : Binding__(xs, calls, Rule__(judg-number, name, (pattern, ctx), outputs, xs-outputs))
                            -> Formula__(<option-to-string-newname(|<type-to-string> type)> name, type, prop)
        where
            conclusion := Pred__(<conc-strings>("'tcheck", <int-to-string> judg-number , "'")
                                , <concat> [<rewrite-pattern> pattern, <rewrite-ctx> ctx, <rewrite-pattern> outputs]);
            premisses := <add-indices; map(\(i, c) -> <rewrite-call(|i, xs, xs-outputs)> c\)> calls;
            formula := <if <[]> calls then !conclusion else !Impl__(premisses, conclusion) end>;
            free-vars-in-rule := <free-vars> formula;
            prop := <if <[]> free-vars-in-rule then !formula else !All__(free-vars-in-rule, formula) end>

    makeFormula(|type) : Formula__(name, prop) -> Formula__(name, type, <rewrite-pattern> prop)

    rewrite-pattern = topdown(try(makeTerm)); topdown(try(rewriteString))
    rewrite-ctx = group(\(c1, c2) -> <equal> (<get-ctx-id> c1, <get-ctx-id> c2)\);
                  map(reverse; \l -> <foldl(\((ctx, i, o), b) -> Pred__(<concat-strings> ["bind", <int-to-string> ctx], <conc> (i, o, [b])) \)> (<Tl> l, <Hd; convert-ctx> l)\)
    
    get-ctx-id = proj(Reset__|1) <+ proj(Ctx__|1) <+ Fst
    convert-ctx : Reset__(ctx) -> Pred__(<concat-strings> ["empty", <int-to-string> ctx])
    convert-ctx : Ctx__(ctx) -> Var__(<concat-strings> ["C", <int-to-string> ctx])
    
    rewrite-call(|i, vars, vars-outputs) : (Lookup__(ctx, inputs), _) ->
        Pred__(<concat-strings> ["lookup", <int-to-string> ctx],
               <conc> (<rewrite-pattern> inputs, <retrieve-outputs(|vars, vars-outputs); rewrite-pattern> i))
    rewrite-call(|i, vars, vars-outputs) : (Judgment__(n, t, binding), _) ->
        Pred__(<conc-strings>("'tcheck", <int-to-string> n, "'"),
               <conc> (<rewrite-pattern> t, <rewrite-ctx> binding, <retrieve-outputs(|vars, vars-outputs); rewrite-pattern> i))
    rewrite-call(|i, vars, vars-outputs) : (Eq__(a, b, _), _) -> Eq__(<rewrite-pattern> a, <rewrite-pattern> b)
    rewrite-call(|i, vars, vars-outputs) : (Neq__(a, b, _), _) -> Neq__(<rewrite-pattern> a, <rewrite-pattern> b)

    retrieve-outputs(|vars, vars-outputs) : i -> <<index(|i)> vars;
                                                  filter(\var ->
                                                                <fetch-elem(?CEq__(var, _, _); proj(CEq__|2))> vars-outputs
                                                            \)>

    // Wrap strings into terms
	wrapString : v -> Term__(v)
	   where <is-string; string-as-chars(map(is-alphanum))> v

	// Wrap all strings that are parameters of Term__ or Pred__ into terms
	rewriteString : Term__(n, args) -> Term__(n, <map(try(wrapString))> args)
	rewriteString : Pred__(n, args) -> Pred__(n, <map(try(wrapString))> args)
	
	// Wrap the constructors of the programming language into terms
	makeTerm : v -> v
	   where <is-string> v
	makeTerm : cons#([]) -> Term__(<lower-case> cons)
	   where <not([])> cons;
	   prop-constructors := ["True", "False"];
             <not(fetch-elem(\prop-cons ->  <equal(|<conc-strings> (prop-cons, "__"), cons)> \))> prop-constructors
    makeTerm : cons#(args) -> Term__(<lower-case> cons, args)
       where <not([])> cons;
             prop-constructors := ["All", "Not", "And", "Or", "Impl", "BiImpl", "Formula",
                                   "Eq", "Neq", "Var", "Pred", "Term", "All", "Exists",
                                   "True", "False"];
             <not(fetch-elem(\prop-cons ->  <equal(|<conc-strings> (prop-cons, "__"), cons)> \))> prop-constructors


strategies
    // Main strategy that apply all transformations to create valid TPTP formulas
	toFOF = makeConjectures; makeVariablesUnique; removeDashes

    // Try to apply all rules that rewrite auxilary constructors
	rewriteAuxCons = rewriteContext <+ rewriteTypingJudgment <+ rewriteMetaVariable
	
	// Rewrite the AST topdown. If an auxilary construtor can be created rewrite it immediatly,
	// otherwise try to create a term. After the first topdown traversal, traverse the AST again
	// topdown to rewrite all relevant strings into terms.
	rewrite = topdown(makeAuxCons < rewriteAuxCons + try(makeTerm)); topdown(try(rewriteString))
	
	// Ensure that all variables are uniquely named and are valid TPTP names. Before that run all Variables are scoped, thus
	// all scoped variables are collected. After this the AST is folded over the collected variables. In the AST the scoped
	// variable nodes are replaced with unscoped fresh variables, variable by variable.
	makeVariablesUnique : ast -> <collect-all(?Var__(_,_)); Dupl;
                                  (id, length; newnames(|"X"); map(\x -> Var__(x)\));
                                  zip; replace-all(|ast)> ast
                                  
	// Dashes in predicate names are not valid in TPTP
	// FIXME: It would be nice, if it is guaranteed, that the renaming creates no collisions
	// FIXME: Try to rename other invalid characters
	removeDashes = topdown(try(\Term__(name, args) -> Term__(<string-replace(|"-", "")> name, args)\ <+
	                           \Term__(name) -> Term__(<string-replace(|"-", "")> name)\))